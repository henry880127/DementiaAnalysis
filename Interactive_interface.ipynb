{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the pickle file\n",
    "data_file_path = '../Dataset/Dementia_paper_dataset_data.pkl'\n",
    "info_file_path = '../Dataset/Dementia_paper_dataset_info.pkl'\n",
    "\n",
    "# Open the pickle file in read mode\n",
    "with open(data_file_path, 'rb') as file:\n",
    "    # Load the data from the pickle file\n",
    "    data = pd.read_pickle(file)\n",
    "\n",
    "# Open the pickle file in read mode\n",
    "with open(info_file_path, 'rb') as file:\n",
    "    # Load the data from the pickle file\n",
    "    info = pd.read_pickle(file)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "data['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and apply fidher's criterion (Abandoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Export the data to an Excel file\n",
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = '../Dataset/Dementia_paper_dataset_data.xlsx'\n",
    "\n",
    "# Create an ExcelWriter object\n",
    "writer = pd.ExcelWriter(excel_file_path, engine='openpyxl')\n",
    "\n",
    "# Loop through the dictionary items and save each dataframe as a separate sheet in the Excel file\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        # Write the dataframe to the Excel file\n",
    "        value.to_excel(writer, sheet_name=key, index=False)\n",
    "\n",
    "# Save the Excel file''\n",
    "writer.close()'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HC: 0, MCI: 1, Dementia: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Dataframe to numpy array in each dictionary\n",
    "data_ndarrays = {}\n",
    "for key, value in data.items():\n",
    "    # Detect if the key is 'Info' and skip it\n",
    "    if key != 'Info':\n",
    "        # Drop the 'ID' and 'Task' columns if they exist\n",
    "        if 'ID' in data[key].columns:\n",
    "            data[key].drop('ID', axis=1, inplace=True)\n",
    "        if 'Task' in data[key].columns:\n",
    "            data[key].drop('Task', axis=1, inplace=True)  \n",
    "        data_ndarrays[key] = value.values\n",
    "    else:\n",
    "        data_ndarrays[key] = value\n",
    "\n",
    "label_ndarrays = {}\n",
    "label_ndarrays_CInonCI = {}\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        label_ndarrays[key] = value['Label'].values\n",
    "        label_ndarrays_CInonCI[key] = value['Label'].values\n",
    "    else:\n",
    "        label_ndarrays[key] = value\n",
    "        label_ndarrays_CInonCI[key] = value\n",
    "\n",
    "# Replace 2 with 1 in label_ndarrays\n",
    "label_ndarrays_CInonCI = {key: np.where(value == 2, 1, value) for key, value in label_ndarrays_CInonCI.items()}\n",
    "\n",
    "print(label_ndarrays['train'])\n",
    "label_ndarrays_CInonCI['train']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of SCD-MCI or SCD-Control in the data set\n",
    "group_ndarrays = {}\n",
    "n_SCD_MCI = {}\n",
    "n_SCD_Control = {}\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        group_ndarrays[key] = value['Group'].values\n",
    "        n_SCD_MCI[key] = np.sum(group_ndarrays[key] == 'SCD-MCI') \n",
    "        n_SCD_Control[key] = np.sum(group_ndarrays[key] == 'SCD-Control') \n",
    "    else:\n",
    "        group_ndarrays[key] = value\n",
    "\n",
    "print(n_SCD_MCI['train'])\n",
    "print(n_SCD_Control['train'])\n",
    "\n",
    "info['train']['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - Relief\n",
    "Ref:\n",
    "- [Feature Selection with RReliefF (Regression)](https://www.kaggle.com/code/jorgesandoval/feature-selection-with-rrelieff-regression/notebook)\n",
    "- [sklearn-relief](https://gitlab.com/moongoal/sklearn-relief/-/blob/master/README.md?ref_type=heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data organizing and feature selection(fisher score)\n",
    "import os\n",
    "import sklearn_relief as relief\n",
    "\n",
    "# Train & Valid data organizing\n",
    "data_train_valid = np.concatenate([data_ndarrays['train'], data_ndarrays['valid']], axis=0)\n",
    "label_train_valid = np.concatenate([label_ndarrays_CInonCI['train'], label_ndarrays_CInonCI['valid']], axis=0)\n",
    "\n",
    "# Independent test data organizing\n",
    "data_test = data_ndarrays['test']\n",
    "label_test = label_ndarrays_CInonCI['test']\n",
    "\n",
    "# Feature selection - filter_based\n",
    "rf = relief.Relief(n_features=200, n_jobs=7)\n",
    "rf.fit_transform(data_train_valid, label_train_valid)\n",
    "relief_scores = rf.w_\n",
    "relief_idx = np.argsort(relief_scores)[::-1] # sort in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Add-one-feature-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Create the SVM classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/LDA/5Fold_test/Relief-AOFI'\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim+1)):\n",
    "    data_CV = data_train_valid[:, relief_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, relief_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/')\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(relief_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'relief_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'relief_idx': relief_idx, 'feature_type': data['train'].columns[relief_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential feature selection\n",
    "Sequential feature selection (Forward or Backward) on features with top-200 fisher's scores\n",
    "Reference: \n",
    "- [API](https://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/#example-7-using-the-selected-feature-subset-for-making-new-predictions)\n",
    "- [This stackoverflow post](https://stackoverflow.com/questions/55609339/how-to-perform-feature-selection-with-gridsearchcv-in-sklearn-in-python) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Create the LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "bool_SFS = False\n",
    "if bool_SFS: folder_path = '../Results/Classification/LDA/5Fold_test/Relief-SFS'\n",
    "else: folder_path = '../Results/Classification/LDA/5Fold_test/Relief-SBS'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "# max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "max_dim = 200\n",
    "\n",
    "# Create the SequentialFeatureSelector object\n",
    "sfs = SFS(estimator=lda, k_features=(1, max_dim), forward=bool_SFS, scoring='accuracy', cv=5, n_jobs=7, verbose=2)\n",
    "\n",
    "# Train the model with SequentialFeatureSelector\n",
    "sfs.fit(data_train_valid[:, relief_idx[:max_dim]], label_train_valid)\n",
    "\n",
    "# Get the best feature set\n",
    "best_feature_idx_ = sfs.k_feature_idx_\n",
    "best_feature_idx_ = relief_idx[[best_feature_idx_]]\n",
    "best_feature_set = data['train'].columns[best_feature_idx_]\n",
    "\n",
    "best_score = sfs.k_score_\n",
    "\n",
    "# Append the loop index and accCV to the dataframe\n",
    "df_accCV = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "# Get the best model\n",
    "best_model = lda.fit(data_train_valid[:, best_feature_idx_], label_train_valid)\n",
    "best_test_score = best_model.score(data_test[:, best_feature_idx_], label_test)\n",
    "\n",
    "# loop through the selected features in df_accCV and concat test_score to the dataframe\n",
    "for idx, row in df_accCV.iterrows():\n",
    "    feature_idx = relief_idx[[row.feature_idx]]\n",
    "    best_model = lda.fit(data_train_valid[:, feature_idx], label_train_valid)\n",
    "    test_score = best_model.score(data_test[:, feature_idx], label_test)\n",
    "    df_accCV.loc[idx, 'test_score'] = test_score\n",
    "\n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/')\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(relief_idx[[row.feature_idx]]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'relief_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'relief_idx': relief_idx, 'feature_type': data['train'].columns[relief_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file\n",
    "\n",
    "print('done')\n",
    "print('best_score:', best_score)\n",
    "print('best_feature_idx:', best_feature_idx_)\n",
    "print('best_feature_set:', best_feature_set)\n",
    "print('best_test_score:', best_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Add-one-feature-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,41) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 10, 100, 500, 1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear','rbf']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/SVM/5Fold_test/Relief-AOFI'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim + 1)):\n",
    "    data_CV = data_train_valid[:, relief_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, relief_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "    \n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/') # Specify the folder path to save models\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder) # Create the folder if it does not exist\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(relief_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'relief_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'relief_idx': relief_idx, 'feature_type': data['train'].columns[relief_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using SVM and 5Fold-CV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut, ParameterGrid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,21) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 10, 100, 500, 1000]\n",
    "\n",
    "\n",
    "# Create multiple parameter set based on all posible combination of the parameter grids\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear']}\n",
    "param_grid_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "\n",
    "# Specify the folder path\n",
    "bool_forward = False\n",
    "if bool_forward: folder_path = '../Results/Classification/SVM/5Fold_test/Relief-SFS'\n",
    "else: folder_path = '../Results/Classification/SVM/5Fold_test/Relief-SBS'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "# Create the grid_search_results object\n",
    "class grid_search_results():\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.df = pd.DataFrame(columns=['avg_scores', 'test_scores', 'best_params', 'feature_idx'])\n",
    "\n",
    "    # Iterate the grid_search results if the validated score is higher than the previous one\n",
    "    def iterate_results(self, df_accCV, params):\n",
    "        if self.df.avg_scores.empty:\n",
    "            self.df.avg_scores = df_accCV.avg_score\n",
    "            self.df.test_scores = df_accCV.test_score\n",
    "            self.df.best_params = pd.Series([f'C:{params[\"C\"]}, gamma:{params[\"gamma\"]}, kernel:{params[\"kernel\"]}']*len(df_accCV.avg_score))\n",
    "            self.df.feature_idx = df_accCV.feature_idx\n",
    "        else:\n",
    "            for idx in range(len(df_accCV.avg_score)):\n",
    "                if df_accCV.avg_score.iloc[idx] > self.df.avg_scores.iloc[idx]:\n",
    "                    self.df.avg_scores.iloc[idx] = df_accCV.avg_score.iloc[idx]\n",
    "                    self.df.test_scores.iloc[idx] = df_accCV.test_score.iloc[idx]\n",
    "                    self.df.best_params.iloc[idx] = f'C:{params[\"C\"]}, gamma:{params[\"gamma\"]}, kernel:{params[\"kernel\"]}'\n",
    "                    self.df.feature_idx.iloc[idx] = df_accCV.feature_idx.iloc[idx]\n",
    "\n",
    "    def save_results(self):\n",
    "        self.df.to_csv(os.path.join(self.folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "\n",
    "gsr = grid_search_results(folder_path)\n",
    "\n",
    "for idx_grid_search, params in enumerate(param_grid_list):\n",
    "    print('params:', params)\n",
    "    C = params['C']\n",
    "    gamma = params['gamma']\n",
    "    kernel = params['kernel']\n",
    "    # Create the SVM classifier\n",
    "    svm = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "\n",
    "    # Create the variable to store the results\n",
    "    df_accCV =list()\n",
    "\n",
    "    # Define the maximum number of features\n",
    "    # max_dim = int(label_train_valid.shape[0]/2)  \n",
    "    max_dim = 200\n",
    "\n",
    "    # Create the SequentialFeatureSelector object\n",
    "    sfs = SFS(estimator=svm, k_features=(1, max_dim), forward=bool_forward, scoring='accuracy', cv=5, n_jobs=10, verbose=2)\n",
    "\n",
    "    # Train the model with SequentialFeatureSelector\n",
    "    sfs.fit(data_train_valid[:, relief_idx[:max_dim]], label_train_valid)\n",
    "\n",
    "    # Get the best feature set\n",
    "    best_feature_idx_ = sfs.k_feature_idx_\n",
    "    best_feature_idx_ = relief_idx[[best_feature_idx_]]\n",
    "    best_feature_set = data['train'].columns[best_feature_idx_]\n",
    "\n",
    "    best_score = sfs.k_score_\n",
    "\n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = lda.fit(data_train_valid[:, best_feature_idx_], label_train_valid)\n",
    "    best_test_score = best_model.score(data_test[:, best_feature_idx_], label_test)\n",
    "\n",
    "    # loop through the selected features in df_accCV and concat test_score to the dataframe\n",
    "    for idx, row in tqdm(df_accCV.iterrows()):\n",
    "        feature_idx = relief_idx[[row.feature_idx]]\n",
    "        best_model = lda.fit(data_train_valid[:, feature_idx], label_train_valid)\n",
    "        test_score = best_model.score(data_test[:, feature_idx], label_test)\n",
    "        df_accCV.loc[idx, 'test_score'] = test_score\n",
    "\n",
    "        # Save the best model to a file\n",
    "        model_folder = os.path.join(folder_path, 'Models/')\n",
    "        if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "        model_file = os.path.join(model_folder, 'best_model_'+str(idx)+'.joblib')\n",
    "        dump(best_model, model_file)  # Save the best model to a file\n",
    "        pd.Series(relief_idx[[row.feature_idx]]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "    # Iterate the grid_search results\n",
    "    gsr.iterate_results(df_accCV, params)\n",
    "\n",
    "# Save the dataframe to csv\n",
    "gsr.save_results()\n",
    "\n",
    "# Create a dictionary with 'relief_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'relief_idx': relief_idx, 'feature_type': data['train'].columns[relief_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file\n",
    "\n",
    "print('done')\n",
    "print('best_score:', best_score)\n",
    "print('best_feature_idx:', best_feature_idx_)\n",
    "print('best_feature_set:', best_feature_set)\n",
    "print('best_test_score:', best_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection - Fisher's Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data organizing and feature selection(fisher score)\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "\n",
    "# Train & Valid data organizing\n",
    "data_train_valid = np.concatenate([data_ndarrays['train'], data_ndarrays['valid']], axis=0)\n",
    "label_train_valid = np.concatenate([label_ndarrays_CInonCI['train'], label_ndarrays_CInonCI['valid']], axis=0)\n",
    "\n",
    "# Independent test data organizing\n",
    "data_test = data_ndarrays['test']\n",
    "label_test = label_ndarrays_CInonCI['test']\n",
    "\n",
    "# Feature selection - filter_based\n",
    "f_selection = f_selection()\n",
    "fisher_scores = f_selection.fisher_score(data_train_valid, label_train_valid)\n",
    "fisher_idx = np.argsort(fisher_scores)[::-1] # sort in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Add-one-feature-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Create the SVM classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/LDA/5Fold_test/AOFI'\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim+1)):\n",
    "    data_CV = data_train_valid[:, fisher_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, fisher_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/')\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(fisher_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential feature selection\n",
    "Sequential feature selection (Forward or Backward) on features with top-200 fisher's scores\n",
    "Reference: \n",
    "- [API](https://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/#example-7-using-the-selected-feature-subset-for-making-new-predictions)\n",
    "- [This stackoverflow post](https://stackoverflow.com/questions/55609339/how-to-perform-feature-selection-with-gridsearchcv-in-sklearn-in-python) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Create the LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "bool_SFS = False\n",
    "if bool_SFS: folder_path = '../Results/Classification/LDA/5Fold_test/SFS'\n",
    "else: folder_path = '../Results/Classification/LDA/5Fold_test/SBS'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "# max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "max_dim = 200\n",
    "\n",
    "# Create the SequentialFeatureSelector object\n",
    "sfs = SFS(estimator=lda, k_features=(1, max_dim), forward=bool_SFS, scoring='accuracy', cv=5, n_jobs=7, verbose=2)\n",
    "\n",
    "# Train the model with SequentialFeatureSelector\n",
    "sfs.fit(data_train_valid[:, fisher_idx[:max_dim]], label_train_valid)\n",
    "\n",
    "# Get the best feature set\n",
    "best_feature_idx_ = sfs.k_feature_idx_\n",
    "best_feature_idx_ = fisher_idx[[best_feature_idx_]]\n",
    "best_feature_set = data['train'].columns[best_feature_idx_]\n",
    "\n",
    "best_score = sfs.k_score_\n",
    "\n",
    "# Append the loop index and accCV to the dataframe\n",
    "df_accCV = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "# Get the best model\n",
    "best_model = lda.fit(data_train_valid[:, best_feature_idx_], label_train_valid)\n",
    "best_test_score = best_model.score(data_test[:, best_feature_idx_], label_test)\n",
    "\n",
    "# loop through the selected features in df_accCV and concat test_score to the dataframe\n",
    "for idx, row in df_accCV.iterrows():\n",
    "    feature_idx = fisher_idx[[row.feature_idx]]\n",
    "    best_model = lda.fit(data_train_valid[:, feature_idx], label_train_valid)\n",
    "    test_score = best_model.score(data_test[:, feature_idx], label_test)\n",
    "    df_accCV.loc[idx, 'test_score'] = test_score\n",
    "\n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/')\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(fisher_idx[[row.feature_idx]]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file\n",
    "\n",
    "print('done')\n",
    "print('best_score:', best_score)\n",
    "print('best_feature_idx:', best_feature_idx_)\n",
    "print('best_feature_set:', best_feature_set)\n",
    "print('best_test_score:', best_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Add-one-feature-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,41) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 10, 100, 500, 1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear','rbf']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/SVM/5Fold_test/AOFI'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim + 1)):\n",
    "    data_CV = data_train_valid[:, fisher_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, fisher_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "    \n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/') # Specify the folder path to save models\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder) # Create the folder if it does not exist\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(fisher_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using SVM and 5Fold-CV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut, ParameterGrid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,21) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 10, 100, 500, 1000]\n",
    "\n",
    "\n",
    "# Create multiple parameter set based on all posible combination of the parameter grids\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear']}\n",
    "param_grid_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "\n",
    "# Specify the folder path\n",
    "bool_forward = False\n",
    "if bool_forward: folder_path = '../Results/Classification/SVM/5Fold_test/SFS'\n",
    "else: folder_path = '../Results/Classification/SVM/5Fold_test/SBS'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "# Create the grid_search_results object\n",
    "class grid_search_results():\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.df = pd.DataFrame(columns=['avg_scores', 'test_scores', 'best_params', 'feature_idx'])\n",
    "\n",
    "    # Iterate the grid_search results if the validated score is higher than the previous one\n",
    "    def iterate_results(self, df_accCV, params):\n",
    "        if self.df.avg_scores.empty:\n",
    "            self.df.avg_scores = df_accCV.avg_score\n",
    "            self.df.test_scores = df_accCV.test_score\n",
    "            self.df.best_params = pd.Series([f'C:{params[\"C\"]}, gamma:{params[\"gamma\"]}, kernel:{params[\"kernel\"]}']*len(df_accCV.avg_score))\n",
    "            self.df.feature_idx = df_accCV.feature_idx\n",
    "        else:\n",
    "            for idx in range(len(df_accCV.avg_score)):\n",
    "                if df_accCV.avg_score.iloc[idx] > self.df.avg_scores.iloc[idx]:\n",
    "                    self.df.avg_scores.iloc[idx] = df_accCV.avg_score.iloc[idx]\n",
    "                    self.df.test_scores.iloc[idx] = df_accCV.test_score.iloc[idx]\n",
    "                    self.df.best_params.iloc[idx] = f'C:{params[\"C\"]}, gamma:{params[\"gamma\"]}, kernel:{params[\"kernel\"]}'\n",
    "                    self.df.feature_idx.iloc[idx] = df_accCV.feature_idx.iloc[idx]\n",
    "\n",
    "    def save_results(self):\n",
    "        self.df.to_csv(os.path.join(self.folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "\n",
    "gsr = grid_search_results(folder_path)\n",
    "\n",
    "for idx_grid_search, params in enumerate(param_grid_list):\n",
    "    print('params:', params)\n",
    "    C = params['C']\n",
    "    gamma = params['gamma']\n",
    "    kernel = params['kernel']\n",
    "    # Create the SVM classifier\n",
    "    svm = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "\n",
    "    # Create the variable to store the results\n",
    "    df_accCV =list()\n",
    "\n",
    "    # Define the maximum number of features\n",
    "    # max_dim = int(label_train_valid.shape[0]/2)  \n",
    "    max_dim = 200\n",
    "\n",
    "    # Create the SequentialFeatureSelector object\n",
    "    sfs = SFS(estimator=svm, k_features=(1, max_dim), forward=bool_forward, scoring='accuracy', cv=5, n_jobs=10, verbose=2)\n",
    "\n",
    "    # Train the model with SequentialFeatureSelector\n",
    "    sfs.fit(data_train_valid[:, fisher_idx[:max_dim]], label_train_valid)\n",
    "\n",
    "    # Get the best feature set\n",
    "    best_feature_idx_ = sfs.k_feature_idx_\n",
    "    best_feature_idx_ = fisher_idx[[best_feature_idx_]]\n",
    "    best_feature_set = data['train'].columns[best_feature_idx_]\n",
    "\n",
    "    best_score = sfs.k_score_\n",
    "\n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = lda.fit(data_train_valid[:, best_feature_idx_], label_train_valid)\n",
    "    best_test_score = best_model.score(data_test[:, best_feature_idx_], label_test)\n",
    "\n",
    "    # loop through the selected features in df_accCV and concat test_score to the dataframe\n",
    "    for idx, row in tqdm(df_accCV.iterrows()):\n",
    "        feature_idx = fisher_idx[[row.feature_idx]]\n",
    "        best_model = lda.fit(data_train_valid[:, feature_idx], label_train_valid)\n",
    "        test_score = best_model.score(data_test[:, feature_idx], label_test)\n",
    "        df_accCV.loc[idx, 'test_score'] = test_score\n",
    "\n",
    "        # Save the best model to a file\n",
    "        model_folder = os.path.join(folder_path, 'Models/')\n",
    "        if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "        model_file = os.path.join(model_folder, 'best_model_'+str(idx)+'.joblib')\n",
    "        dump(best_model, model_file)  # Save the best model to a file\n",
    "        pd.Series(fisher_idx[[row.feature_idx]]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "    # Iterate the grid_search results\n",
    "    gsr.iterate_results(df_accCV, params)\n",
    "\n",
    "# Save the dataframe to csv\n",
    "gsr.save_results()\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file\n",
    "\n",
    "print('done')\n",
    "print('best_score:', best_score)\n",
    "print('best_feature_idx:', best_feature_idx_)\n",
    "print('best_feature_set:', best_feature_set)\n",
    "print('best_test_score:', best_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Experiments: Classification using \"Scales\" as input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# organizing - scores of different mental scales\n",
    "scales_df = {}\n",
    "scales_names = ['GDS_total', 'MMSE_total', 'IADL_total', 'ADL_total', 'CDR_total', 'MoCA_total']\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        scales_df[key] = value[scales_names]\n",
    "    else:\n",
    "        scales_df[key] = value\n",
    "\n",
    "scales_train_valid = pd.concat([scales_df['train'], scales_df['valid']], axis=0)\n",
    "scales_test = scales_df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "print('label_train_valid: ',label_train_valid.shape)\n",
    "print('scales_train_valid: ',scales_train_valid.shape)\n",
    "\n",
    "# Create the SVM classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification using scales/LDA/5Fold_test/'\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "# Create the df to store the results\n",
    "df_accCV = []\n",
    "\n",
    "for scale in scales_names:\n",
    "    print(scale)\n",
    "    data_CV = scales_train_valid[scale].values.reshape(-1,1)\n",
    "    data_test = scales_test[scale].values.reshape(-1,1)\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test, label_test)\n",
    "\n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'scale': scale, 'best_score': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Create the SVM classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification using scales/LDA/5Fold_test/'\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim+1)):\n",
    "    data_CV = data_train_valid[:, fisher_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, fisher_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/')\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(fisher_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE (recursive feature elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# create the LDA classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/LDA/5Fold_test/RFE'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different feature types input to LDA/SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model_ML import Model_ML\n",
    "# Extract the columns that contain the specific feature type\n",
    "feature_names = data['train'].columns.values\n",
    "unique_types_feat = [col.split('_')[0] for col in feature_names]\n",
    "unique_types_feat = np.unique(unique_types_feat)\n",
    "print(unique_types_feat)  \n",
    "#   >> ['Coh' 'Corr' 'DFA' 'HFD100' 'ID' 'KFD' 'LogBP' 'PLI' 'PLV' \n",
    "#       'PLZC' 'RP-I' 'RP-II' 'RP-III' 'RatioPower' 'SampEn-I' 'SampEn-II' 'Task']\n",
    "unique_types_feat = np.delete(unique_types_feat, np.where(unique_types_feat == 'ID'))\n",
    "unique_types_feat = np.delete(unique_types_feat, np.where(unique_types_feat == 'Task'))\n",
    "print(unique_types_feat)    \n",
    "\n",
    "specific_features = {}\n",
    "for featur_type in unique_types_feat:\n",
    "    for key, value in data.items():\n",
    "        # Detect if the key is 'Info' and skip it\n",
    "        if key != 'Info':\n",
    "            # Drop the 'ID' and 'Task' columns if they exist\n",
    "            if 'ID' in data[key].columns:\n",
    "                data[key].drop('ID', axis=1, inplace=True)\n",
    "            if 'Task' in data[key].columns:\n",
    "                data[key].drop('Task', axis=1, inplace=True)  \n",
    "            specific_features[key] = data[key].loc[:, [col for col in feature_names if (featur_type == col.split('_')[0])]]\n",
    "        else:\n",
    "            specific_features[key] = data[key]\n",
    "\n",
    "    model_ML = Model_ML(specific_features, info, \n",
    "                        folder_path_LDA = f'../Results/Classification/LDA/10Fold_test/{featur_type}/',\n",
    "                        folder_path_SVM= f'../Results/Classification/SVM/10Fold_test/{featur_type}/')\n",
    "    \n",
    "    print(f'Feature type: {featur_type}')\n",
    "    print('LDA:')\n",
    "    model_ML.CV_LDA()\n",
    "    print('SVM:')\n",
    "    model_ML.CV_SVM()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connectivity Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create connectivity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracht the names of channels\n",
    "feature_names = data['train'].columns.values\n",
    "unique_types_feat = 'KFD'\n",
    "channels = feature_names.copy()\n",
    "channels = [col.split('_')[1] for col in channels if unique_types_feat == col.split('_')[0]]\n",
    "print(channels)\n",
    "\n",
    "# Extract the columns that contain the specific feature type\n",
    "feature_names = data['train'].columns.values\n",
    "unique_types_feat = ['PLI']\n",
    "\n",
    "specific_features = {}\n",
    "for featur_type in unique_types_feat:\n",
    "    for key, value in data.items():\n",
    "        # Detect if the key is 'Info' and skip it\n",
    "        if key != 'Info':\n",
    "            # Drop the 'ID' and 'Task' columns if they exist\n",
    "            if 'ID' in data[key].columns:\n",
    "                data[key].drop('ID', axis=1, inplace=True)\n",
    "            if 'Task' in data[key].columns:\n",
    "                data[key].drop('Task', axis=1, inplace=True)  \n",
    "            specific_features[key] = data[key].loc[:, [col for col in feature_names if (featur_type == col.split('_')[0])]]\n",
    "        else:\n",
    "            specific_features[key] = data[key]\n",
    "\n",
    "specific_features['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connectivity_maps(data):\n",
    "    # Extracht the names of channels\n",
    "    feature_names = data['train'].columns.values\n",
    "    unique_types_feat = 'KFD'\n",
    "    channels = feature_names.copy()\n",
    "    channels = [col.split('_')[1] for col in channels if unique_types_feat == col.split('_')[0]]\n",
    "    print('channels:\\n',channels)\n",
    "\n",
    "    # Extract the columns that contain the specific feature type\n",
    "    feature_names = data['train'].columns.values\n",
    "    unique_types_feat = ['PLI']\n",
    "\n",
    "    specific_features = {}\n",
    "    for featur_type in unique_types_feat:\n",
    "        for key, value in data.items():\n",
    "            # Detect if the key is 'Info' and skip it\n",
    "            if key != 'Info':\n",
    "                # Drop the 'ID' and 'Task' columns if they exist\n",
    "                if 'ID' in data[key].columns:\n",
    "                    data[key].drop('ID', axis=1, inplace=True)\n",
    "                if 'Task' in data[key].columns:\n",
    "                    data[key].drop('Task', axis=1, inplace=True)  \n",
    "                specific_features[key] = data[key].loc[:, [col for col in feature_names if (featur_type == col.split('_')[0])]]\n",
    "            else:\n",
    "                specific_features[key] = data[key]\n",
    "\n",
    "    # specific_features['train'].head()\n",
    "    PLI_matrix_subject = []\n",
    "    bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "    connectivity_map_dataset = {}\n",
    "    for dataset_key, value in data.items():\n",
    "        connectivity_map = {}\n",
    "        for band in bands:\n",
    "            connectivity_map[band] = np.zeros((len(specific_features[dataset_key]), len(channels), len(channels)))\n",
    "            for n_subject in range(len(specific_features[dataset_key])):\n",
    "                # PLI_matrix__single_subject = np.zeros((len(specific_features['train']), len(channels), len(channels)))\n",
    "                for ch_1 in range(len(channels)):\n",
    "                    for ch_2 in range(ch_1,len(channels)):\n",
    "                        if ch_1 != ch_2:\n",
    "                            connectivity_map[band][n_subject, ch_1, ch_2] = specific_features['train'].loc[int(n_subject), f'{unique_types_feat[0]}_{band}_{channels[ch_1]}-{channels[ch_2]}']\n",
    "                            connectivity_map[band][n_subject, ch_2, ch_1] = connectivity_map[band][n_subject, ch_1, ch_2]\n",
    "        connectivity_map_dataset[dataset_key] = connectivity_map\n",
    "    return connectivity_map_dataset\n",
    "\n",
    "connectivity_map_dataset = create_connectivity_maps(data)\n",
    "\n",
    "connectivity_map_dataset['train']['delta'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing - scores of different mental scales\n",
    "scales_df = {}\n",
    "scales_names = ['GDS_total', 'MMSE_total', 'IADL_total', 'ADL_total', 'CDR_total', 'MoCA_total']\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        scales_df[key] = value[scales_names]\n",
    "    else:\n",
    "        scales_df[key] = value\n",
    "\n",
    "scales_train_valid = pd.concat([scales_df['train'], scales_df['valid']], axis=0)\n",
    "scales_test = scales_df['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision values VS. Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "from scipy import stats\n",
    "\n",
    "# Create the SVM classifier\n",
    "svr = SVR()\n",
    "linR = LinearRegression()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,21) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1,10,100,1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['rbf']}\n",
    "param_grid_linR = {'fit_intercept': [True]}\n",
    "\n",
    "\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "\n",
    "# Specify the folder paths\n",
    "folder_path = '../Results/Classification/SVM/AOFI_smallerGrid_10Fold/'\n",
    "model_folder_path = os.path.join(folder_path, 'Models/')\n",
    "fisher_idx_path = os.path.join(folder_path, 'fisher_idx_series.csv') # Specify the file path\n",
    "fisher_idx = pd.read_csv(fisher_idx_path)['fisher_idx'].values # Load the fisher_idx from the file\n",
    "\n",
    "for scale_name, scale in scales_train_valid.items():\n",
    "    print(scale_name+':')\n",
    "    _scale_train_valid = scale.values\n",
    "    _scale_test = scales_test[scale_name].values\n",
    "\n",
    "    df_scoreCV =list()\n",
    "    for idx_AOFI in tqdm(range(1, max_dim+1)):\n",
    "        model_file = os.path.join(model_folder_path, 'best_model_'+str(idx_AOFI)+'.joblib') # Specify the file path\n",
    "        model = load(model_file) # Load the model from the file\n",
    "        decision_values = model.decision_function(data_train_valid[:, fisher_idx[:idx_AOFI]]) # Get the decision values\n",
    "\n",
    "        data_CV = decision_values.reshape(-1, 1) # Reshape the decision values to a 2D array\n",
    "\n",
    "        # Create the GridSearchCV object\n",
    "        # print(\"grid_search start\")\n",
    "        grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=10, n_jobs=10)\n",
    "        # Train the model with gridsearchCV\n",
    "        grid_search.fit(data_CV, _scale_train_valid)\n",
    "        # print(\"grid_search end\")\n",
    "\n",
    "        # Get the best parameters and best score\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        # print(\"best_score:\",best_score)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Get the decision values of test data\n",
    "        decision_values_test = model.decision_function(data_test[:, fisher_idx[:idx_AOFI]]).reshape(-1, 1)\n",
    "        test_score = best_model.score(decision_values_test, _scale_test) # Get the test score af regression\n",
    "        correlation_test = stats.pearsonr(decision_values_test.flatten(), _scale_test.flatten()) # Get the correlation coefficient of test data VS scale\n",
    "\n",
    "        # Combine the decision values of train, valid and test data\n",
    "        decision_values_all = np.concatenate([data_CV, decision_values_test], axis=0)\n",
    "        _scale_all = np.concatenate([_scale_train_valid, _scale_test], axis=0)\n",
    "\n",
    "        # Append the loop index and scoreCV to the dataframe\n",
    "        df_scoreCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score, \n",
    "                           'correlation_coef_all':stats.pearsonr(decision_values_all.flatten(), _scale_all.flatten())[0],\n",
    "                           'p-value_all':stats.pearsonr(decision_values_all.flatten(), _scale_all.flatten())[1],\n",
    "                           'correlation_coef_train':stats.pearsonr(data_CV.flatten(), _scale_train_valid.flatten())[0],\n",
    "                           'p-value_train':stats.pearsonr(data_CV.flatten(), _scale_train_valid.flatten())[1],\n",
    "                           'correlation_coef_test':correlation_test[0],\n",
    "                           'p-value_test':correlation_test[1]})\n",
    "        \n",
    "        \n",
    "    # Save the dataframe to csv\n",
    "    df_scoreCV = pd.DataFrame(df_scoreCV) # Convert the list to a dataframe\n",
    "    folder_decisionValue_vs_scale = os.path.join(folder_path, 'decisionValue_vs_scale/rbf_SVR/', scale_name) # Specify the folder path\n",
    "    if not os.path.exists(folder_decisionValue_vs_scale):    os.makedirs(folder_decisionValue_vs_scale)\n",
    "    df_scoreCV.to_csv(os.path.join(folder_decisionValue_vs_scale, 'df_scoreCV.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abandon\n",
    "# feature selction for regression using pearson's correlation - filter based\n",
    "\n",
    "# select the specific scale for the regression\n",
    "scale_idx = 1 #'GDS_total','MMSE_total','IADL_total', 'ADL_total', 'CDR_total', 'MoCA_total'\n",
    "_scale_train_valid = scales_train_valid.iloc[:, scale_idx]\n",
    "_scale_test = scales_test.iloc[:, scale_idx]\n",
    "\n",
    "print(data_train_valid.shape, scales_train_valid.shape)\n",
    "pearson_scores = f_selection.pearson_coef(data_train_valid, _scale_train_valid)\n",
    "pearson_idx = np.argsort(pearson_scores)[::-1] # sort in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature configuration VS. Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "\n",
    "# Create the SVM classifier\n",
    "svr = SVR()\n",
    "linR = LinearRegression()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,21) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 100,  1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear','rbf']}\n",
    "param_grid_linR = {'fit_intercept': [True]}\n",
    "\n",
    "\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for scale_name, scale in scales_train_valid.items():\n",
    "    print(scale_name+':')\n",
    "    _scale_train_valid = scale\n",
    "    _scale_test = scales_test[scale_name]\n",
    "\n",
    "    # Feature selection - filter_based - pearson's correlation\n",
    "    pearson_scores = f_selection.pearson_coef(data_train_valid, _scale_train_valid)\n",
    "    pearson_idx = np.argsort(pearson_scores)[::-1] # sort in descending order\n",
    "\n",
    "    # Specify the folder path\n",
    "    folder_path = f'../Results/Regression/SVR/AOFI_10Fold/{scale_name}/'\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "    df_scoreCV =list()\n",
    "    for idx_AOFI in tqdm(range(1, max_dim + 1)):\n",
    "        data_CV = data_train_valid[:, pearson_idx[:idx_AOFI]]\n",
    "        \n",
    "        # Create the GridSearchCV object\n",
    "        grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=10, n_jobs=10)\n",
    "\n",
    "        # Train the model with gridsearchCV\n",
    "        grid_search.fit(data_CV, _scale_train_valid)\n",
    "\n",
    "        # Get the best parameters and best score\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        test_score = best_model.score(data_test[:, pearson_idx[:idx_AOFI]], _scale_test)\n",
    "        \n",
    "        # Append the loop index and accCV to the dataframe\n",
    "        df_scoreCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "        # Save the best model to a file\n",
    "        model_folder = os.path.join(folder_path, 'Models/')\n",
    "        if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "        model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "        dump(best_model, model_file)\n",
    "        pd.Series(pearson_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "\n",
    "    # Save the dataframe to csv\n",
    "    df_scoreCV = pd.DataFrame(df_scoreCV) # Convert the list to a dataframe\n",
    "    df_scoreCV.to_csv(os.path.join(folder_path, 'df_scoreCV.csv'), index=False)\n",
    "\n",
    "    # Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "    pearson_idx_DF = {'pearson_idx': pearson_idx, 'feature_type': data['train'].columns[pearson_idx]}\n",
    "    pearson_idx_DF = pd.DataFrame(pearson_idx_DF) # Convert the dictionary to a DataFrame\n",
    "    pearson_idx_DF.to_csv(os.path.join(folder_path, 'fpearson_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Ref: https://machinelearningmastery.com/deep-learning-models-for-multi-output-regression/\n",
    "# Ref: https://machinelearningmastery.com/neural-network-models-for-combined-classification-and-regression/\n",
    "# Don't know why, but when setting the loss function, follow the following order: regression, classification\n",
    "class Model_2outputs():\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 n_classes,\n",
    "                 optimizer=Adam(beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "                 lr=0.000001,\n",
    "                 model_name='Model_2outputs',\n",
    "                 epochs=100,\n",
    "                 batch_size=32,\n",
    "                 log_path='Models/logs',\n",
    "                 loss = ['mse', 'sparse_categorical_crossentropy'],\n",
    "                 **kwargs):\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.optimizer = optimizer\n",
    "        # self.optimizer.lr = lr\n",
    "        self.model_name = model_name\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.log_path = log_path\n",
    "        self.loss = loss\n",
    "\n",
    "        # use **kwargs to set the new value of below args.\n",
    "        self.f1_average = 'binary' if self.n_classes == 2 else 'macro'\n",
    "        self.nNeurons_common = 64\n",
    "        self.nNeurons_net1 = [64,32]\n",
    "        self.nNeurons_net2 = [64,32]\n",
    "        self.dropout_rate = 0.5\n",
    "        self.norm_rate = 0.25\n",
    "        self.monitor = 'val_loss' # save_best_only based on this monitor\n",
    "\n",
    "        for k in kwargs.keys():\n",
    "            self.__setattr__(k, kwargs[k])\n",
    "\n",
    "    def build(self):\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "\n",
    "        common_layer = Dense(self.nNeurons_common, activation='relu')(input_layer)\n",
    "        # common_layer = Dense(20, activation='relu', kernel_initializer='he_normal')(input_layer)\n",
    "        # common_layer = Dense(10, activation='relu', kernel_initializer='he_normal')(common_layer)\n",
    "    \n",
    "        # sub-network 1  for classification\n",
    "        sub_net1 = Dense(self.nNeurons_net1[0], activation='relu')(common_layer)\n",
    "        sub_net1 = Dense(self.nNeurons_net1[1], activation='relu')(sub_net1)\n",
    "        sub_net1 = Dropout(self.dropout_rate)(sub_net1)\n",
    "        sub_net1_output = Dense(self.n_classes, activation='softmax', name='output_classification')(sub_net1)\n",
    "        # sub_net1_output = Dense(self.n_classes, activation='softmax')(common_layer) #test open source's structure from ref\n",
    "\n",
    "        # sub-network 2  for regrssion\n",
    "        sub_net2 = Dense(self.nNeurons_net2[0], activation='relu')(common_layer)\n",
    "        sub_net2 = Dense(self.nNeurons_net2[0], activation='relu')(sub_net2)\n",
    "        sub_net2 = Dropout(self.dropout_rate)(sub_net2)\n",
    "        sub_net2_output = Dense(1, activation='linear', name='output_regression')(sub_net2)\n",
    "        # sub_net2_output = Dense(1, activation='linear')(common_layer) #test open source's structure from ref\n",
    "\n",
    "        # Combine both sub-network outputs\n",
    "        combined_output = [sub_net2_output, sub_net1_output]\n",
    "\n",
    "        # Define the model with input and combined output\n",
    "        model = Model(inputs=input_layer, outputs=combined_output)\n",
    "        \n",
    "        # Compile the model\n",
    "        # Don't know why, but when setting the loss function, follow the following order: regression, classification\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics={'output_classification': 'accuracy', 'output_regression': self.coeff_determination})\n",
    "\n",
    "        # plot the model\n",
    "        file_path = self.log_path + '/' + self.model_name + '/' + self.model_name + '.h5'\n",
    "        plot_model(model, to_file=self.log_path + '/model.png', show_shapes=True)\n",
    "\n",
    "        # Print model summary\n",
    "        model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train,  y_train_reg, y_train_cat, X_val, y_val_cat, y_val_reg):\n",
    "        # Define the callbacks\n",
    "        file_path = self.log_path + '/' + self.model_name + '/' + self.model_name + '.h5'\n",
    "        if not os.path.exists(self.log_path + '/' + self.model_name):\n",
    "            os.makedirs(self.log_path + '/' + self.model_name)\n",
    "        checkpointer = ModelCheckpoint(monitor=self.monitor, filepath=file_path, \n",
    "                                       verbose=1, save_best_only=True, save_weights_only=True)\n",
    "        \n",
    "        model = self.build()\n",
    "        history = model.fit(X_train,[y_train_reg, y_train_cat],\n",
    "                            epochs=self.epochs, batch_size=self.batch_size,\n",
    "                            validation_data=(X_val, [y_val_cat, y_val_reg]), verbose=1,\n",
    "                            callbacks=[checkpointer])\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def score(self, X_test, y_test_reg, y_test_cat):\n",
    "        model = self.build() # Build the model\n",
    "        model.load_weights(self.log_path + '/' + self.model_name + '/' + self.model_name + '.h5') # Load the best model\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss) # Compile the model\n",
    "\n",
    "        start = time.time()  # Record the start time\n",
    "        [y_pred_reg, y_pred_cat] = model.predict(X_test) # Predict the test data\n",
    "        end = time.time() # Record the end time\n",
    "\n",
    "        # performance evaluation of classification(category)\n",
    "        y_pred_cat = np.argmax(y_pred_cat, axis=-1).astype(int) # Get the predicted category\n",
    "        acc = accuracy_score(y_test_cat, y_pred_cat)\n",
    "        print('Accuracy: %.3f' % acc)\n",
    "\n",
    "        # performance evaluation of regression\n",
    "        print(y_test_reg.shape, y_pred_reg.shape)\n",
    "        score = r2_score(y_test_reg, y_pred_reg) # Calculate the mean absolute error\n",
    "        print('r2_score: %.3f' % score)\n",
    "       \n",
    "        loss = model.evaluate(x=X_test, y=[y_test_reg, y_test_cat], batch_size=self.batch_size)\n",
    "\n",
    "        evaluation = {'loss': loss, \n",
    "                      'accuracy': acc,\n",
    "                      'r2_score': score, \n",
    "                      'prediction_time': end-start}\n",
    "        \n",
    "        Y = {'y_true': [y_test_cat, y_test_reg], \n",
    "             'y_pred': [y_pred_cat, y_pred_reg]}\n",
    "        return Y, evaluation\n",
    "    \n",
    "    def coeff_determination(self, y_true, y_pred):\n",
    "        SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "        SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "        return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the following variables:\n",
    "# train_features, train_targets_reg, train_targets_cat\n",
    "# val_features, val_targets_reg, val_targets_cat\n",
    "# test_features, test_targets_reg, test_targets_cat\n",
    "\n",
    "# Define the scale to be used for regression\n",
    "scale_name = 'MMSE_total'\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_train = np.array(data_ndarrays['train'])\n",
    "y_train_reg = np.array(scales_df['train'][scale_name])\n",
    "y_train_cat = np.array(label_ndarrays_CInonCI['train'])\n",
    "\n",
    "X_val = np.array(data_ndarrays['valid'])\n",
    "y_val_reg = np.array(scales_df['valid'][scale_name])\n",
    "y_val_cat = np.array(label_ndarrays_CInonCI['valid'])\n",
    "\n",
    "X_test = np.array(data_ndarrays['test'])\n",
    "y_test_reg = np.array(scales_df['test'][scale_name])\n",
    "y_test_cat = np.array(label_ndarrays_CInonCI['test'])\n",
    "\n",
    "# Normalize the data if needed\n",
    "# You can use sklearn's StandardScaler or MinMaxScaler for normalization\n",
    "\n",
    "# Print the shapes of the data to verify\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train_reg shape:\", y_train_reg.shape)\n",
    "print(\"y_train_cat shape:\", y_train_cat.shape)\n",
    "\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val_reg shape:\", y_val_reg.shape)\n",
    "print(\"y_val_cat shape:\", y_val_cat.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test_reg shape:\", y_test_reg.shape)\n",
    "print(\"y_test_cat shape:\", y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "n_features = X_train.shape[1]  # Define the number of features\n",
    "n_class = len(unique(y_train_cat))  # Define the number of classes\n",
    "\n",
    "# define model\n",
    "model_2outputs = Model_2outputs(n_features, n_class, epochs=500, batch_size=10)\n",
    "\n",
    "history=model_2outputs.fit(X_train, y_train_reg, y_train_cat, X_val, y_val_reg, y_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('validation')\n",
    "model_2outputs.score(X_val, y_val_reg, y_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')\n",
    "model_2outputs.score(X_test, y_test_reg, y_test_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFGPU_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
