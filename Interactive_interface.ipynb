{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Task</th>\n",
       "      <th>Coh_delta_T5-T3</th>\n",
       "      <th>Coh_delta_T5-F7</th>\n",
       "      <th>Coh_delta_T5-O1</th>\n",
       "      <th>Coh_delta_T5-Cp3</th>\n",
       "      <th>Coh_delta_T5-Fc3</th>\n",
       "      <th>Coh_delta_T5-Fp1</th>\n",
       "      <th>Coh_delta_T5-Fcz</th>\n",
       "      <th>Coh_delta_T5-Cpz</th>\n",
       "      <th>...</th>\n",
       "      <th>Corr_Cp4-O2</th>\n",
       "      <th>Corr_Cp4-F8</th>\n",
       "      <th>Corr_Cp4-T4</th>\n",
       "      <th>Corr_Cp4-T6</th>\n",
       "      <th>Corr_O2-F8</th>\n",
       "      <th>Corr_O2-T4</th>\n",
       "      <th>Corr_O2-T6</th>\n",
       "      <th>Corr_F8-T4</th>\n",
       "      <th>Corr_F8-T6</th>\n",
       "      <th>Corr_T4-T6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTUH_0004</td>\n",
       "      <td>Rest</td>\n",
       "      <td>0.739369</td>\n",
       "      <td>0.701256</td>\n",
       "      <td>0.759699</td>\n",
       "      <td>0.741979</td>\n",
       "      <td>0.482286</td>\n",
       "      <td>0.165846</td>\n",
       "      <td>0.110406</td>\n",
       "      <td>0.291415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765194</td>\n",
       "      <td>0.567678</td>\n",
       "      <td>0.708985</td>\n",
       "      <td>0.803361</td>\n",
       "      <td>0.404576</td>\n",
       "      <td>0.661505</td>\n",
       "      <td>0.919683</td>\n",
       "      <td>0.717551</td>\n",
       "      <td>0.520095</td>\n",
       "      <td>0.783182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGMHKL_0002</td>\n",
       "      <td>Rest</td>\n",
       "      <td>0.814006</td>\n",
       "      <td>0.304687</td>\n",
       "      <td>0.923202</td>\n",
       "      <td>0.659374</td>\n",
       "      <td>0.235388</td>\n",
       "      <td>0.263912</td>\n",
       "      <td>0.233530</td>\n",
       "      <td>0.494247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594284</td>\n",
       "      <td>0.311152</td>\n",
       "      <td>0.518404</td>\n",
       "      <td>0.688676</td>\n",
       "      <td>0.192620</td>\n",
       "      <td>0.477090</td>\n",
       "      <td>0.762633</td>\n",
       "      <td>0.449235</td>\n",
       "      <td>0.383965</td>\n",
       "      <td>0.661592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NTUH_0011</td>\n",
       "      <td>Rest</td>\n",
       "      <td>0.756742</td>\n",
       "      <td>0.273296</td>\n",
       "      <td>0.838798</td>\n",
       "      <td>0.849737</td>\n",
       "      <td>0.255621</td>\n",
       "      <td>0.145847</td>\n",
       "      <td>0.172226</td>\n",
       "      <td>0.420560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648830</td>\n",
       "      <td>0.432738</td>\n",
       "      <td>0.592082</td>\n",
       "      <td>0.750562</td>\n",
       "      <td>0.244982</td>\n",
       "      <td>0.558273</td>\n",
       "      <td>0.891249</td>\n",
       "      <td>0.643338</td>\n",
       "      <td>0.400314</td>\n",
       "      <td>0.701446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CGMHKL_0005</td>\n",
       "      <td>Rest</td>\n",
       "      <td>0.755170</td>\n",
       "      <td>0.332022</td>\n",
       "      <td>0.721507</td>\n",
       "      <td>0.514757</td>\n",
       "      <td>0.138277</td>\n",
       "      <td>0.259687</td>\n",
       "      <td>0.193953</td>\n",
       "      <td>0.307590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614496</td>\n",
       "      <td>0.296134</td>\n",
       "      <td>0.239646</td>\n",
       "      <td>0.736570</td>\n",
       "      <td>0.284022</td>\n",
       "      <td>0.345613</td>\n",
       "      <td>0.818268</td>\n",
       "      <td>0.302792</td>\n",
       "      <td>0.371725</td>\n",
       "      <td>0.428486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CGMHKL_0004</td>\n",
       "      <td>Rest</td>\n",
       "      <td>0.651956</td>\n",
       "      <td>0.284282</td>\n",
       "      <td>0.611058</td>\n",
       "      <td>0.573420</td>\n",
       "      <td>0.240884</td>\n",
       "      <td>0.169931</td>\n",
       "      <td>0.155174</td>\n",
       "      <td>0.229636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347948</td>\n",
       "      <td>0.311138</td>\n",
       "      <td>0.429988</td>\n",
       "      <td>0.502850</td>\n",
       "      <td>0.242461</td>\n",
       "      <td>0.377395</td>\n",
       "      <td>0.727081</td>\n",
       "      <td>0.626247</td>\n",
       "      <td>0.420851</td>\n",
       "      <td>0.575280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13052 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Task  Coh_delta_T5-T3  Coh_delta_T5-F7  Coh_delta_T5-O1  \\\n",
       "0    NTUH_0004  Rest         0.739369         0.701256         0.759699   \n",
       "1  CGMHKL_0002  Rest         0.814006         0.304687         0.923202   \n",
       "2    NTUH_0011  Rest         0.756742         0.273296         0.838798   \n",
       "3  CGMHKL_0005  Rest         0.755170         0.332022         0.721507   \n",
       "4  CGMHKL_0004  Rest         0.651956         0.284282         0.611058   \n",
       "\n",
       "   Coh_delta_T5-Cp3  Coh_delta_T5-Fc3  Coh_delta_T5-Fp1  Coh_delta_T5-Fcz  \\\n",
       "0          0.741979          0.482286          0.165846          0.110406   \n",
       "1          0.659374          0.235388          0.263912          0.233530   \n",
       "2          0.849737          0.255621          0.145847          0.172226   \n",
       "3          0.514757          0.138277          0.259687          0.193953   \n",
       "4          0.573420          0.240884          0.169931          0.155174   \n",
       "\n",
       "   Coh_delta_T5-Cpz  ...  Corr_Cp4-O2  Corr_Cp4-F8  Corr_Cp4-T4  Corr_Cp4-T6  \\\n",
       "0          0.291415  ...     0.765194     0.567678     0.708985     0.803361   \n",
       "1          0.494247  ...     0.594284     0.311152     0.518404     0.688676   \n",
       "2          0.420560  ...     0.648830     0.432738     0.592082     0.750562   \n",
       "3          0.307590  ...     0.614496     0.296134     0.239646     0.736570   \n",
       "4          0.229636  ...     0.347948     0.311138     0.429988     0.502850   \n",
       "\n",
       "   Corr_O2-F8  Corr_O2-T4  Corr_O2-T6  Corr_F8-T4  Corr_F8-T6  Corr_T4-T6  \n",
       "0    0.404576    0.661505    0.919683    0.717551    0.520095    0.783182  \n",
       "1    0.192620    0.477090    0.762633    0.449235    0.383965    0.661592  \n",
       "2    0.244982    0.558273    0.891249    0.643338    0.400314    0.701446  \n",
       "3    0.284022    0.345613    0.818268    0.302792    0.371725    0.428486  \n",
       "4    0.242461    0.377395    0.727081    0.626247    0.420851    0.575280  \n",
       "\n",
       "[5 rows x 13052 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the pickle file\n",
    "data_file_path = '../Dataset/Dementia_paper_dataset_data.pkl'\n",
    "info_file_path = '../Dataset/Dementia_paper_dataset_info.pkl'\n",
    "\n",
    "# Open the pickle file in read mode\n",
    "with open(data_file_path, 'rb') as file:\n",
    "    # Load the data from the pickle file\n",
    "    data = pd.read_pickle(file)\n",
    "\n",
    "# Open the pickle file in read mode\n",
    "with open(info_file_path, 'rb') as file:\n",
    "    # Load the data from the pickle file\n",
    "    info = pd.read_pickle(file)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "data['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and apply fidher's criterion (Abandoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Export the data to an Excel file\n",
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path for the Excel file\n",
    "excel_file_path = '../Dataset/Dementia_paper_dataset_data.xlsx'\n",
    "\n",
    "# Create an ExcelWriter object\n",
    "writer = pd.ExcelWriter(excel_file_path, engine='openpyxl')\n",
    "\n",
    "# Loop through the dictionary items and save each dataframe as a separate sheet in the Excel file\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        # Write the dataframe to the Excel file\n",
    "        value.to_excel(writer, sheet_name=key, index=False)\n",
    "\n",
    "# Save the Excel file''\n",
    "writer.close()'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HC: 0, MCI: 1, Dementia: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import numpy as np\\n# Dataframe to numpy array in each dictionary\\ndata_ndarrays = {}\\nfor key, value in data.items():\\n    # Detect if the key is 'Info' and skip it\\n    if key != 'Info':\\n        # Drop the 'ID' and 'Task' columns if they exist\\n        if 'ID' in data[key].columns:\\n            data[key].drop('ID', axis=1, inplace=True)\\n        if 'Task' in data[key].columns:\\n            data[key].drop('Task', axis=1, inplace=True)  \\n        data_ndarrays[key] = value.values\\n    else:\\n        data_ndarrays[key] = value\\n\\nlabel_ndarrays = {}\\nlabel_ndarrays_CInonCI = {}\\nfor key, value in info.items():\\n    if key != 'Info':\\n        label_ndarrays[key] = value['Label'].values\\n        label_ndarrays_CInonCI[key] = value['Label'].values\\n    else:\\n        label_ndarrays[key] = value\\n        label_ndarrays_CInonCI[key] = value\\n\\n# Replace 2 with 1 in label_ndarrays\\nlabel_ndarrays_CInonCI = {key: np.where(value == 2, 1, value) for key, value in label_ndarrays_CInonCI.items()}\\n\\nprint(label_ndarrays['train'])\\nlabel_ndarrays_CInonCI['train']\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "# Dataframe to numpy array in each dictionary\n",
    "data_ndarrays = {}\n",
    "for key, value in data.items():\n",
    "    # Detect if the key is 'Info' and skip it\n",
    "    if key != 'Info':\n",
    "        # Drop the 'ID' and 'Task' columns if they exist\n",
    "        if 'ID' in data[key].columns:\n",
    "            data[key].drop('ID', axis=1, inplace=True)\n",
    "        if 'Task' in data[key].columns:\n",
    "            data[key].drop('Task', axis=1, inplace=True)  \n",
    "        data_ndarrays[key] = value.values\n",
    "    else:\n",
    "        data_ndarrays[key] = value\n",
    "\n",
    "label_ndarrays = {}\n",
    "label_ndarrays_CInonCI = {}\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        label_ndarrays[key] = value['Label'].values\n",
    "        label_ndarrays_CInonCI[key] = value['Label'].values\n",
    "    else:\n",
    "        label_ndarrays[key] = value\n",
    "        label_ndarrays_CInonCI[key] = value\n",
    "\n",
    "# Replace 2 with 1 in label_ndarrays\n",
    "label_ndarrays_CInonCI = {key: np.where(value == 2, 1, value) for key, value in label_ndarrays_CInonCI.items()}\n",
    "\n",
    "print(label_ndarrays['train'])\n",
    "label_ndarrays_CInonCI['train']\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Count the number of SCD-MCI or SCD-Control in the data set\n",
    "group_ndarrays = {}\n",
    "n_SCD_MCI = {}\n",
    "n_SCD_Control = {}\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        group_ndarrays[key] = value['Group'].values\n",
    "        n_SCD_MCI[key] = np.sum(group_ndarrays[key] == 'SCD-MCI') \n",
    "        n_SCD_Control[key] = np.sum(group_ndarrays[key] == 'SCD-Control') \n",
    "    else:\n",
    "        group_ndarrays[key] = value\n",
    "\n",
    "print(n_SCD_MCI['train'])\n",
    "print(n_SCD_Control['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# data organizing and feature selection(fisher score)\\nimport os\\nfrom feature_related import feature_selection as f_selection  # Import the feature_selection module\\n\\n# Train & Valid data organizing\\ndata_train_valid = np.concatenate([data_ndarrays['train'], data_ndarrays['valid']], axis=0)\\nlabel_train_valid = np.concatenate([label_ndarrays_CInonCI['train'], label_ndarrays_CInonCI['valid']], axis=0)\\n\\n# Independent test data organizing\\ndata_test = data_ndarrays['test']\\nlabel_test = label_ndarrays_CInonCI['test']\\n\\n# Feature selection - filter_based\\nf_selection = f_selection()\\nfisher_scores = f_selection.fisher_score(data_train_valid, label_train_valid)\\nfisher_idx = np.argsort(fisher_scores)[::-1] # sort in descending order\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# data organizing and feature selection(fisher score)\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "\n",
    "# Train & Valid data organizing\n",
    "data_train_valid = np.concatenate([data_ndarrays['train'], data_ndarrays['valid']], axis=0)\n",
    "label_train_valid = np.concatenate([label_ndarrays_CInonCI['train'], label_ndarrays_CInonCI['valid']], axis=0)\n",
    "\n",
    "# Independent test data organizing\n",
    "data_test = data_ndarrays['test']\n",
    "label_test = label_ndarrays_CInonCI['test']\n",
    "\n",
    "# Feature selection - filter_based\n",
    "f_selection = f_selection()\n",
    "fisher_scores = f_selection.fisher_score(data_train_valid, label_train_valid)\n",
    "fisher_idx = np.argsort(fisher_scores)[::-1] # sort in descending order'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different feature types input to LDA/SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coh' 'Corr' 'DFA' 'HFD100' 'KFD' 'LogBP' 'PLI' 'PLV' 'PLZC' 'RP-I'\n",
      " 'RP-II' 'RP-III' 'RatioPower' 'SampEn-I' 'SampEn-II']\n",
      "['Coh' 'Corr' 'DFA' 'HFD100' 'KFD' 'LogBP' 'PLI' 'PLV' 'PLZC' 'RP-I'\n",
      " 'RP-II' 'RP-III' 'RatioPower' 'SampEn-I' 'SampEn-II']\n",
      "Feature type: Coh\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 39.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [16:06<00:00,  9.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: Corr\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 68.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [38:45<00:00, 22.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: DFA\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 74.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [13:05<00:00,  7.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: HFD100\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 72.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [04:19<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: KFD\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 75.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [02:20<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: LogBP\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 67.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [9:18:58<00:00, 319.41s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: PLI\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 59.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [07:21<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: PLV\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 61.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [22:50<00:00, 13.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: PLZC\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 73.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [02:53<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: RP-I\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:03<00:00, 28.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [1:10:56<00:00, 40.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: RP-II\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [38:05<00:00, 21.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: RP-III\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [17:11:25<00:00, 589.39s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: RatioPower\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:03<00:00, 33.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [17:25<00:00,  9.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: SampEn-I\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 39.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [13:42<00:00,  7.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature type: SampEn-II\n",
      "LDA:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:02<00:00, 38.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [14:42<00:00,  8.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from Model_ML import Model_ML\n",
    "# Extract the columns that contain the specific feature type\n",
    "feature_names = data['train'].columns.values\n",
    "unique_types_feat = [col.split('_')[0] for col in feature_names]\n",
    "unique_types_feat = np.unique(unique_types_feat)\n",
    "print(unique_types_feat)  \n",
    "#   >> ['Coh' 'Corr' 'DFA' 'HFD100' 'ID' 'KFD' 'LogBP' 'PLI' 'PLV' \n",
    "#       'PLZC' 'RP-I' 'RP-II' 'RP-III' 'RatioPower' 'SampEn-I' 'SampEn-II' 'Task']\n",
    "unique_types_feat = np.delete(unique_types_feat, np.where(unique_types_feat == 'ID'))\n",
    "unique_types_feat = np.delete(unique_types_feat, np.where(unique_types_feat == 'Task'))\n",
    "print(unique_types_feat)    \n",
    "\n",
    "specific_features = {}\n",
    "for featur_type in unique_types_feat:\n",
    "    for key, value in data.items():\n",
    "        # Detect if the key is 'Info' and skip it\n",
    "        if key != 'Info':\n",
    "            # Drop the 'ID' and 'Task' columns if they exist\n",
    "            if 'ID' in data[key].columns:\n",
    "                data[key].drop('ID', axis=1, inplace=True)\n",
    "            if 'Task' in data[key].columns:\n",
    "                data[key].drop('Task', axis=1, inplace=True)  \n",
    "            specific_features[key] = data[key].loc[:, [col for col in feature_names if (featur_type == col.split('_')[0])]]\n",
    "        else:\n",
    "            specific_features[key] = data[key]\n",
    "\n",
    "    model_ML = Model_ML(specific_features, info, \n",
    "                        folder_path_LDA = f'../Results/Classification/LDA/10Fold_test/{featur_type}/',\n",
    "                        folder_path_SVM= f'../Results/Classification/SVM/10Fold_test/{featur_type}/')\n",
    "    \n",
    "    print(f'Feature type: {featur_type}')\n",
    "    print('LDA:')\n",
    "    model_ML.CV_LDA()\n",
    "    print('SVM:')\n",
    "    model_ML.CV_SVM()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying the data using LDA and LOO-CV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "from feature_related import feature_selection as f_selection  # Import the feature_selection module\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Create the SVM classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'solver': ['svd']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/LDA/10Fold_test/'\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim+1)):\n",
    "    data_CV = data_train_valid[:, fisher_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=10, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, fisher_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/')\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(fisher_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "    \n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,41) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 10, 100, 500, 1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear','rbf']}\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = '../Results/Classification/SVM/AOFI_smallerGrid_10Fold/'\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "df_accCV =list()\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for idx_AOFI in tqdm(range(1, max_dim + 1)):\n",
    "    data_CV = data_train_valid[:, fisher_idx[:idx_AOFI]]\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=10, n_jobs=7)\n",
    "\n",
    "    # Train the model with gridsearchCV\n",
    "    grid_search.fit(data_CV, label_train_valid)\n",
    "\n",
    "    # Get the best parameters and best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(data_test[:, fisher_idx[:idx_AOFI]], label_test)\n",
    "    \n",
    "    # Append the loop index and accCV to the dataframe\n",
    "    df_accCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "    \n",
    "    # Save the best model to a file\n",
    "    model_folder = os.path.join(folder_path, 'Models/') # Specify the folder path to save models\n",
    "    if not os.path.exists(model_folder):    os.makedirs(model_folder) # Create the folder if it does not exist\n",
    "    model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "    dump(best_model, model_file)  # Save the best model to a file\n",
    "    pd.Series(fisher_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "\n",
    "# Save the dataframe to csv\n",
    "df_accCV = pd.DataFrame(df_accCV) # Convert the list to a dataframe\n",
    "df_accCV.to_csv(os.path.join(folder_path, 'df_accCV.csv'), index=False)\n",
    "\n",
    "# Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "fisher_idx_DF = {'fisher_idx': fisher_idx, 'feature_type': data['train'].columns[fisher_idx]}\n",
    "fisher_idx_DF = pd.DataFrame(fisher_idx_DF) # Convert the dictionary to a DataFrame\n",
    "fisher_idx_DF.to_csv(os.path.join(folder_path, 'fisher_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizing - scores of different mental scales\n",
    "scales_df = {}\n",
    "scales_names = ['GDS_total', 'MMSE_total', 'IADL_total', 'ADL_total', 'CDR_total', 'MoCA_total']\n",
    "for key, value in info.items():\n",
    "    if key != 'Info':\n",
    "        scales_df[key] = value[scales_names]\n",
    "    else:\n",
    "        scales_df[key] = value\n",
    "\n",
    "scales_train_valid = pd.concat([scales_df['train'], scales_df['valid']], axis=0)\n",
    "scales_test = scales_df['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision values VS. Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "from scipy import stats\n",
    "\n",
    "# Create the SVM classifier\n",
    "svr = SVR()\n",
    "linR = LinearRegression()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,21) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1,10,100,1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['rbf']}\n",
    "param_grid_linR = {'fit_intercept': [True]}\n",
    "\n",
    "\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "\n",
    "# Specify the folder paths\n",
    "folder_path = '../Results/Classification/SVM/AOFI_smallerGrid_10Fold/'\n",
    "model_folder_path = os.path.join(folder_path, 'Models/')\n",
    "fisher_idx_path = os.path.join(folder_path, 'fisher_idx_series.csv') # Specify the file path\n",
    "fisher_idx = pd.read_csv(fisher_idx_path)['fisher_idx'].values # Load the fisher_idx from the file\n",
    "\n",
    "for scale_name, scale in scales_train_valid.items():\n",
    "    print(scale_name+':')\n",
    "    _scale_train_valid = scale.values\n",
    "    _scale_test = scales_test[scale_name].values\n",
    "\n",
    "    df_scoreCV =list()\n",
    "    for idx_AOFI in tqdm(range(1, max_dim+1)):\n",
    "        model_file = os.path.join(model_folder_path, 'best_model_'+str(idx_AOFI)+'.joblib') # Specify the file path\n",
    "        model = load(model_file) # Load the model from the file\n",
    "        decision_values = model.decision_function(data_train_valid[:, fisher_idx[:idx_AOFI]]) # Get the decision values\n",
    "\n",
    "        data_CV = decision_values.reshape(-1, 1) # Reshape the decision values to a 2D array\n",
    "\n",
    "        # Create the GridSearchCV object\n",
    "        # print(\"grid_search start\")\n",
    "        grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=10, n_jobs=10)\n",
    "        # Train the model with gridsearchCV\n",
    "        grid_search.fit(data_CV, _scale_train_valid)\n",
    "        # print(\"grid_search end\")\n",
    "\n",
    "        # Get the best parameters and best score\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        # print(\"best_score:\",best_score)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Get the decision values of test data\n",
    "        decision_values_test = model.decision_function(data_test[:, fisher_idx[:idx_AOFI]]).reshape(-1, 1)\n",
    "        test_score = best_model.score(decision_values_test, _scale_test) # Get the test score af regression\n",
    "        correlation_test = stats.pearsonr(decision_values_test.flatten(), _scale_test.flatten()) # Get the correlation coefficient of test data VS scale\n",
    "\n",
    "        # Combine the decision values of train, valid and test data\n",
    "        decision_values_all = np.concatenate([data_CV, decision_values_test], axis=0)\n",
    "        _scale_all = np.concatenate([_scale_train_valid, _scale_test], axis=0)\n",
    "\n",
    "        # Append the loop index and scoreCV to the dataframe\n",
    "        df_scoreCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score, \n",
    "                           'correlation_coef_all':stats.pearsonr(decision_values_all.flatten(), _scale_all.flatten())[0],\n",
    "                           'p-value_all':stats.pearsonr(decision_values_all.flatten(), _scale_all.flatten())[1],\n",
    "                           'correlation_coef_train':stats.pearsonr(data_CV.flatten(), _scale_train_valid.flatten())[0],\n",
    "                           'p-value_train':stats.pearsonr(data_CV.flatten(), _scale_train_valid.flatten())[1],\n",
    "                           'correlation_coef_test':correlation_test[0],\n",
    "                           'p-value_test':correlation_test[1]})\n",
    "        \n",
    "        \n",
    "    # Save the dataframe to csv\n",
    "    df_scoreCV = pd.DataFrame(df_scoreCV) # Convert the list to a dataframe\n",
    "    folder_decisionValue_vs_scale = os.path.join(folder_path, 'decisionValue_vs_scale/rbf_SVR/', scale_name) # Specify the folder path\n",
    "    if not os.path.exists(folder_decisionValue_vs_scale):    os.makedirs(folder_decisionValue_vs_scale)\n",
    "    df_scoreCV.to_csv(os.path.join(folder_decisionValue_vs_scale, 'df_scoreCV.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abandon\n",
    "# feature selction for regression using pearson's correlation - filter based\n",
    "\n",
    "# select the specific scale for the regression\n",
    "scale_idx = 1 #'GDS_total','MMSE_total','IADL_total', 'ADL_total', 'CDR_total', 'MoCA_total'\n",
    "_scale_train_valid = scales_train_valid.iloc[:, scale_idx]\n",
    "_scale_test = scales_test.iloc[:, scale_idx]\n",
    "\n",
    "print(data_train_valid.shape, scales_train_valid.shape)\n",
    "pearson_scores = f_selection.pearson_coef(data_train_valid, _scale_train_valid)\n",
    "pearson_idx = np.argsort(pearson_scores)[::-1] # sort in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature configuration VS. Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from joblib import dump, load\n",
    "\n",
    "# Create the SVM classifier\n",
    "svr = SVR()\n",
    "linR = LinearRegression()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "gamma_range = np.linspace(-100,100,21) #-100,-95,...,95,100\n",
    "gamma_range = 1.05**gamma_range # 1.05^-100,1.05^-95,...,1.05^95,1.05^100\n",
    "gamma_range = 1 / 2*(np.square(gamma_range))  # gamma = 1 / (2*sigma)^2, based on the SVC documentation\n",
    "gamma_range = gamma_range.tolist()\n",
    "C_range = [1, 100,  1000]\n",
    "param_grid = {'C': C_range, 'gamma': gamma_range, 'kernel': ['linear','rbf']}\n",
    "param_grid_linR = {'fit_intercept': [True]}\n",
    "\n",
    "\n",
    "max_dim = int(label_train_valid.shape[0]/2)  # Define the maximum number of features\n",
    "for scale_name, scale in scales_train_valid.items():\n",
    "    print(scale_name+':')\n",
    "    _scale_train_valid = scale\n",
    "    _scale_test = scales_test[scale_name]\n",
    "\n",
    "    # Feature selection - filter_based - pearson's correlation\n",
    "    pearson_scores = f_selection.pearson_coef(data_train_valid, _scale_train_valid)\n",
    "    pearson_idx = np.argsort(pearson_scores)[::-1] # sort in descending order\n",
    "\n",
    "    # Specify the folder path\n",
    "    folder_path = f'../Results/Regression/SVR/AOFI_10Fold/{scale_name}/'\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "\n",
    "    df_scoreCV =list()\n",
    "    for idx_AOFI in tqdm(range(1, max_dim + 1)):\n",
    "        data_CV = data_train_valid[:, pearson_idx[:idx_AOFI]]\n",
    "        \n",
    "        # Create the GridSearchCV object\n",
    "        grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=10, n_jobs=10)\n",
    "\n",
    "        # Train the model with gridsearchCV\n",
    "        grid_search.fit(data_CV, _scale_train_valid)\n",
    "\n",
    "        # Get the best parameters and best score\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        test_score = best_model.score(data_test[:, pearson_idx[:idx_AOFI]], _scale_test)\n",
    "        \n",
    "        # Append the loop index and accCV to the dataframe\n",
    "        df_scoreCV.append({'#features': idx_AOFI, 'best_CVscore': best_score, 'best_params': best_params, 'test_score': test_score})\n",
    "\n",
    "        # Save the best model to a file\n",
    "        model_folder = os.path.join(folder_path, 'Models/')\n",
    "        if not os.path.exists(model_folder):    os.makedirs(model_folder)\n",
    "        model_file = os.path.join(model_folder, 'best_model_'+str(idx_AOFI)+'.joblib')\n",
    "        dump(best_model, model_file)\n",
    "        pd.Series(pearson_idx[:idx_AOFI]).to_csv(model_file+'_features_idx.csv', index=False)  # Save the best features index to a file\n",
    "\n",
    "    # Save the dataframe to csv\n",
    "    df_scoreCV = pd.DataFrame(df_scoreCV) # Convert the list to a dataframe\n",
    "    df_scoreCV.to_csv(os.path.join(folder_path, 'df_scoreCV.csv'), index=False)\n",
    "\n",
    "    # Create a dictionary with 'fisher_idx' and 'feature_type' as keys\n",
    "    pearson_idx_DF = {'pearson_idx': pearson_idx, 'feature_type': data['train'].columns[pearson_idx]}\n",
    "    pearson_idx_DF = pd.DataFrame(pearson_idx_DF) # Convert the dictionary to a DataFrame\n",
    "    pearson_idx_DF.to_csv(os.path.join(folder_path, 'fpearson_idx_series.csv'), index=False) # Save the DataFrame to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Ref: https://machinelearningmastery.com/deep-learning-models-for-multi-output-regression/\n",
    "# Ref: https://machinelearningmastery.com/neural-network-models-for-combined-classification-and-regression/\n",
    "# Don't know why, but when setting the loss function, follow the following order: regression, classification\n",
    "class Model_2outputs():\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 n_classes,\n",
    "                 optimizer=Adam(beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "                 lr=0.000001,\n",
    "                 model_name='Model_2outputs',\n",
    "                 epochs=100,\n",
    "                 batch_size=32,\n",
    "                 log_path='Models/logs',\n",
    "                 loss = ['mse', 'sparse_categorical_crossentropy'],\n",
    "                 **kwargs):\n",
    "        self.input_dim = input_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.optimizer = optimizer\n",
    "        # self.optimizer.lr = lr\n",
    "        self.model_name = model_name\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.log_path = log_path\n",
    "        self.loss = loss\n",
    "\n",
    "        # use **kwargs to set the new value of below args.\n",
    "        self.f1_average = 'binary' if self.n_classes == 2 else 'macro'\n",
    "        self.nNeurons_common = 64\n",
    "        self.nNeurons_net1 = [64,32]\n",
    "        self.nNeurons_net2 = [64,32]\n",
    "        self.dropout_rate = 0.5\n",
    "        self.norm_rate = 0.25\n",
    "        self.monitor = 'val_loss' # save_best_only based on this monitor\n",
    "\n",
    "        for k in kwargs.keys():\n",
    "            self.__setattr__(k, kwargs[k])\n",
    "\n",
    "    def build(self):\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "\n",
    "        common_layer = Dense(self.nNeurons_common, activation='relu')(input_layer)\n",
    "        # common_layer = Dense(20, activation='relu', kernel_initializer='he_normal')(input_layer)\n",
    "        # common_layer = Dense(10, activation='relu', kernel_initializer='he_normal')(common_layer)\n",
    "    \n",
    "        # sub-network 1  for classification\n",
    "        sub_net1 = Dense(self.nNeurons_net1[0], activation='relu')(common_layer)\n",
    "        sub_net1 = Dense(self.nNeurons_net1[1], activation='relu')(sub_net1)\n",
    "        sub_net1 = Dropout(self.dropout_rate)(sub_net1)\n",
    "        sub_net1_output = Dense(self.n_classes, activation='softmax', name='output_classification')(sub_net1)\n",
    "        # sub_net1_output = Dense(self.n_classes, activation='softmax')(common_layer) #test open source's structure from ref\n",
    "\n",
    "        # sub-network 2  for regrssion\n",
    "        sub_net2 = Dense(self.nNeurons_net2[0], activation='relu')(common_layer)\n",
    "        sub_net2 = Dense(self.nNeurons_net2[0], activation='relu')(sub_net2)\n",
    "        sub_net2 = Dropout(self.dropout_rate)(sub_net2)\n",
    "        sub_net2_output = Dense(1, activation='linear', name='output_regression')(sub_net2)\n",
    "        # sub_net2_output = Dense(1, activation='linear')(common_layer) #test open source's structure from ref\n",
    "\n",
    "        # Combine both sub-network outputs\n",
    "        combined_output = [sub_net2_output, sub_net1_output]\n",
    "\n",
    "        # Define the model with input and combined output\n",
    "        model = Model(inputs=input_layer, outputs=combined_output)\n",
    "        \n",
    "        # Compile the model\n",
    "        # Don't know why, but when setting the loss function, follow the following order: regression, classification\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss, metrics={'output_classification': 'accuracy', 'output_regression': self.coeff_determination})\n",
    "\n",
    "        # plot the model\n",
    "        file_path = self.log_path + '/' + self.model_name + '/' + self.model_name + '.h5'\n",
    "        plot_model(model, to_file=self.log_path + '/model.png', show_shapes=True)\n",
    "\n",
    "        # Print model summary\n",
    "        model.summary()\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train,  y_train_reg, y_train_cat, X_val, y_val_cat, y_val_reg):\n",
    "        # Define the callbacks\n",
    "        file_path = self.log_path + '/' + self.model_name + '/' + self.model_name + '.h5'\n",
    "        if not os.path.exists(self.log_path + '/' + self.model_name):\n",
    "            os.makedirs(self.log_path + '/' + self.model_name)\n",
    "        checkpointer = ModelCheckpoint(monitor=self.monitor, filepath=file_path, \n",
    "                                       verbose=1, save_best_only=True, save_weights_only=True)\n",
    "        \n",
    "        model = self.build()\n",
    "        history = model.fit(X_train,[y_train_reg, y_train_cat],\n",
    "                            epochs=self.epochs, batch_size=self.batch_size,\n",
    "                            validation_data=(X_val, [y_val_cat, y_val_reg]), verbose=1,\n",
    "                            callbacks=[checkpointer])\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def score(self, X_test, y_test_reg, y_test_cat):\n",
    "        model = self.build() # Build the model\n",
    "        model.load_weights(self.log_path + '/' + self.model_name + '/' + self.model_name + '.h5') # Load the best model\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss) # Compile the model\n",
    "\n",
    "        start = time.time()  # Record the start time\n",
    "        [y_pred_reg, y_pred_cat] = model.predict(X_test) # Predict the test data\n",
    "        end = time.time() # Record the end time\n",
    "\n",
    "        # performance evaluation of classification(category)\n",
    "        y_pred_cat = np.argmax(y_pred_cat, axis=-1).astype(int) # Get the predicted category\n",
    "        acc = accuracy_score(y_test_cat, y_pred_cat)\n",
    "        print('Accuracy: %.3f' % acc)\n",
    "\n",
    "        # performance evaluation of regression\n",
    "        print(y_test_reg.shape, y_pred_reg.shape)\n",
    "        score = r2_score(y_test_reg, y_pred_reg) # Calculate the mean absolute error\n",
    "        print('r2_score: %.3f' % score)\n",
    "       \n",
    "        loss = model.evaluate(x=X_test, y=[y_test_reg, y_test_cat], batch_size=self.batch_size)\n",
    "\n",
    "        evaluation = {'loss': loss, \n",
    "                      'accuracy': acc,\n",
    "                      'r2_score': score, \n",
    "                      'prediction_time': end-start}\n",
    "        \n",
    "        Y = {'y_true': [y_test_cat, y_test_reg], \n",
    "             'y_pred': [y_pred_cat, y_pred_reg]}\n",
    "        return Y, evaluation\n",
    "    \n",
    "    def coeff_determination(self, y_true, y_pred):\n",
    "        SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "        SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "        return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the following variables:\n",
    "# train_features, train_targets_reg, train_targets_cat\n",
    "# val_features, val_targets_reg, val_targets_cat\n",
    "# test_features, test_targets_reg, test_targets_cat\n",
    "\n",
    "# Define the scale to be used for regression\n",
    "scale_name = 'MMSE_total'\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "X_train = np.array(data_ndarrays['train'])\n",
    "y_train_reg = np.array(scales_df['train'][scale_name])\n",
    "y_train_cat = np.array(label_ndarrays_CInonCI['train'])\n",
    "\n",
    "X_val = np.array(data_ndarrays['valid'])\n",
    "y_val_reg = np.array(scales_df['valid'][scale_name])\n",
    "y_val_cat = np.array(label_ndarrays_CInonCI['valid'])\n",
    "\n",
    "X_test = np.array(data_ndarrays['test'])\n",
    "y_test_reg = np.array(scales_df['test'][scale_name])\n",
    "y_test_cat = np.array(label_ndarrays_CInonCI['test'])\n",
    "\n",
    "# Normalize the data if needed\n",
    "# You can use sklearn's StandardScaler or MinMaxScaler for normalization\n",
    "\n",
    "# Print the shapes of the data to verify\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train_reg shape:\", y_train_reg.shape)\n",
    "print(\"y_train_cat shape:\", y_train_cat.shape)\n",
    "\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val_reg shape:\", y_val_reg.shape)\n",
    "print(\"y_val_cat shape:\", y_val_cat.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test_reg shape:\", y_test_reg.shape)\n",
    "print(\"y_test_cat shape:\", y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "n_features = X_train.shape[1]  # Define the number of features\n",
    "n_class = len(unique(y_train_cat))  # Define the number of classes\n",
    "\n",
    "# define model\n",
    "model_2outputs = Model_2outputs(n_features, n_class, epochs=500, batch_size=10)\n",
    "\n",
    "history=model_2outputs.fit(X_train, y_train_reg, y_train_cat, X_val, y_val_reg, y_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('validation')\n",
    "model_2outputs.score(X_val, y_val_reg, y_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')\n",
    "model_2outputs.score(X_test, y_test_reg, y_test_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFGPU_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
