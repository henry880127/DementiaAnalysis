{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Raw data imported.\n",
    "Censored due to privacy concerns.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_Preprocess_EEGNet import Data_Preprocess_EEGNet\n",
    "DPE = Data_Preprocess_EEGNet(data,info)\n",
    "PP_data, label_ndarrays, label_ndarrays_CInonCI = DPE.epoch_based_organizing(z_score=True)\n",
    "\n",
    "def save_results_EEGNet(Y, evaluation, folder_path, csv_name:str):\n",
    "    import pandas as pdpandas\n",
    "    import os\n",
    "    folder_path = folder_path\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "        \n",
    "    evaluation_DF = pd.DataFrame(evaluation, index=[0])\n",
    "    evaluation_DF.to_csv(os.path.join(folder_path, f'evaluation_{csv_name}.csv'), index=False)\n",
    "\n",
    "    Y_DF = pd.DataFrame(Y)\n",
    "    Y_DF.to_csv(os.path.join(folder_path, f'Y_{csv_name}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGNet\n",
    "- **First apply train-validation-test**\n",
    "- **switch the sequence of train and valid dataset**\n",
    "    - To see whether the EEGNet model remenber the information of train dataset which is fit in the previous model training   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-validation-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EEGNet_function import EEGNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = EEGNet(input_shape=(1, 30, 375),\n",
    "               num_class=2,\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               optimizer=Adam(beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "               epochs=100,\n",
    "               batch_size=100,\n",
    "               es_patience=50,\n",
    "               monitor='val_accuracy',\n",
    "               log_path = 'logs/fold1',\n",
    "               shuffle = True)\n",
    "\n",
    "model.fit(PP_data['train'], label_ndarrays_CInonCI['train'], PP_data['valid'], label_ndarrays_CInonCI['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,evaluation = model.predict( PP_data['valid'], label_ndarrays_CInonCI['valid'])\n",
    "\n",
    "print(evaluation)\n",
    "\n",
    "folder_path = f'./Results/EEGNet/TVT'\n",
    "\n",
    "save_results_EEGNet(Y, evaluation, folder_path, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,evaluation = model.predict(PP_data['test'], label_ndarrays_CInonCI['test'])\n",
    "\n",
    "print(evaluation)\n",
    "\n",
    "folder_path = f'./Results/EEGNet/TVT'\n",
    "\n",
    "save_results_EEGNet(Y, evaluation, folder_path, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train <-> valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from EEGNet_function import EEGNet\n",
    "model = EEGNet(input_shape=(1, 30, 375),\n",
    "               num_class=2,\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               optimizer=Adam(beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "               epochs=100,\n",
    "               batch_size=100,\n",
    "               es_patience=50,\n",
    "               monitor='val_accuracy',\n",
    "               log_path= 'logs/Fold2',\n",
    "               shuffle = True)\n",
    "\n",
    "model.fit(PP_data['valid'], label_ndarrays_CInonCI['valid'], PP_data['train'], label_ndarrays_CInonCI['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,evaluation = model.predict( PP_data['valid'], label_ndarrays_CInonCI['valid'])\n",
    "\n",
    "folder_path = f'./Results/EEGNet/TVT_TVswitch'\n",
    "\n",
    "save_results_EEGNet(Y, evaluation, folder_path, 'valid')\n",
    "\n",
    "Y,evaluation = model.predict( PP_data['train'], label_ndarrays_CInonCI['train'])\n",
    "\n",
    "folder_path = f'./Results/EEGNet/TVT_TVswitch'\n",
    "\n",
    "save_results_EEGNet(Y, evaluation, folder_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict( PP_data['test'], label_ndarrays_CInonCI['test'])\n",
    "\n",
    "folder_path = f'./Results/EEGNet/TVT_TVswitch'\n",
    "\n",
    "save_results_EEGNet(Y, evaluation, folder_path, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hnc import function_hnc\n",
    "\n",
    "path_data = '../data/Dementia_paper_dataset_rawData.hdf5'\n",
    "data = {}\n",
    "data['train'] = function_hnc.hnc_load_data(path_data, 'train/data')\n",
    "data['valid'] = function_hnc.hnc_load_data(path_data, 'valid/data')\n",
    "data['test'] = function_hnc.hnc_load_data(path_data, 'test/data')\n",
    "\n",
    "path_info = '../data/Dementia_paper_dataset_info.pkl'\n",
    "info = {}\n",
    "info['train'] = function_hnc.hnc_load_data(path_info, 'train')\n",
    "info['valid'] = function_hnc.hnc_load_data(path_info, 'valid')\n",
    "info['test'] = function_hnc.hnc_load_data(path_info, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['train_valid'] = np.concatenate([data['train'], data['valid']]) \n",
    "data['train_valid'].shape\n",
    "import pandas as pd\n",
    "info['train_valid'] = pd.concat([info['train'], info['valid']]) \n",
    "info['train_valid'].shape\n",
    "print(info.keys())\n",
    "print(data.keys())\n",
    "keys_to_remove = ['train', 'valid']\n",
    "for key in keys_to_remove:\n",
    "    info.pop(key)\n",
    "    data.pop(key)\n",
    "print(info.keys())\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_based_accuracy(Y, nEpoch_perSub = 40):\n",
    "    idx = 0\n",
    "    subject_correct = []\n",
    "    subject_true_label = []\n",
    "    subject_pred_label = []\n",
    "    nEpoch = Y['y_true'].shape[0]\n",
    "    while idx+nEpoch_perSub <= nEpoch:\n",
    "        subject_true_label.append(np.average(Y['y_true'][idx:idx+nEpoch_perSub])) # access the true label\n",
    "        if np.average(Y['y_true'][idx:idx+nEpoch_perSub] == Y['y_pred'][idx:idx+nEpoch_perSub]) > 0.5:\n",
    "            subject_correct.append(1)\n",
    "            subject_pred_label.append(np.average(Y['y_true'][idx:idx+nEpoch_perSub])) # access the predict label\n",
    "        else:\n",
    "            subject_correct.append(0)\n",
    "            subject_pred_label.append(np.abs(1-np.average(Y['y_true'][idx:idx+nEpoch_perSub]))) # access the predict label\n",
    "        idx += nEpoch_perSub\n",
    "\n",
    "    \n",
    "    subject_correct = np.array(subject_correct)\n",
    "    subject_true_label = np.array(subject_true_label)\n",
    "    subject_pred_label = np.array(subject_pred_label)\n",
    "    \n",
    "    accuracy = np.average(subject_correct)\n",
    "    return subject_correct, accuracy, subject_true_label, subject_pred_label\n",
    "\n",
    "def access_label(info):\n",
    "    label_ndarrays = {}\n",
    "    label_ndarrays_CInonCI = {}\n",
    "    for key, value in info.items():\n",
    "        if key != 'Info':\n",
    "            label_ndarrays[key] = value['Label'].values\n",
    "            label_ndarrays_CInonCI[key] = value['Label'].values\n",
    "        else:\n",
    "            label_ndarrays[key] = value\n",
    "            label_ndarrays_CInonCI[key] = value\n",
    "\n",
    "    # Replace 2 with 1 in label_ndarrays\n",
    "    label_ndarrays_CInonCI = {key: np.where(value == 2, 1, value) for key, value in label_ndarrays_CInonCI.items()}\n",
    "\n",
    "    return label_ndarrays_CInonCI\n",
    "\n",
    "def save_results_EEGNet(Y, evaluation, folder_path, csv_name:str):\n",
    "    import pandas as pdpandas\n",
    "    import os\n",
    "    folder_path = folder_path\n",
    "    # Create the folder if it does not exist\n",
    "    if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "        \n",
    "    evaluation_DF = pd.DataFrame(evaluation, index=[0])\n",
    "    evaluation_DF.to_csv(os.path.join(folder_path, f'evaluation_{csv_name}.csv'), index=False)\n",
    "\n",
    "    Y_DF = pd.DataFrame(Y)\n",
    "    Y_DF.to_csv(os.path.join(folder_path, f'Y_{csv_name}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Hyperparams. or preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'none'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'none'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'none'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': True,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'none'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': True,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': True,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.001,\n",
       "  'scaling': 'minmax'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'z_score'},\n",
       " {'across_channel': False,\n",
       "  'at_each_time_point': False,\n",
       "  'conduct_Czrrf': False,\n",
       "  'dropout_rate': 0.5,\n",
       "  'lr': 0.01,\n",
       "  'scaling': 'minmax'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# scaling = ['z_score', 'minmax', 'none']\n",
    "# conduct_Czrrf = [True, False]\n",
    "# at_each_time_point = [True, False]\n",
    "scaling = ['minmax']\n",
    "conduct_Czrrf = [True, False]\n",
    "at_each_time_point = [True]\n",
    "across_channel = [True]\n",
    "\n",
    "if scaling == 'z_score':\n",
    "    z_score = True\n",
    "    minmax = False\n",
    "elif scaling == 'minmax':\n",
    "    z_score = False\n",
    "    minmax = True \n",
    "else:\n",
    "    z_score = False\n",
    "    minmax = False \n",
    "\n",
    "# Create multiple parameter set based on all posible combination of the parameter grids\n",
    "param_grid = [\n",
    "                 {'scaling': ['z_score', 'minmax', 'none'], \n",
    "                  'conduct_Czrrf': [True, False], \n",
    "                  'at_each_time_point': [True],\n",
    "                  'across_channel': [True],\n",
    "                  'dropout_rate': [0.5],\n",
    "                  'lr': [0.001, 0.01]},\n",
    "                 {'scaling':  ['z_score', 'minmax'], \n",
    "                  'conduct_Czrrf': [True, False],\n",
    "                  'at_each_time_point': [False],\n",
    "                  'across_channel': [True, False],\n",
    "                  'dropout_rate': [0.5],\n",
    "                  'lr': [0.001, 0.01]},\n",
    "                ]\n",
    "param_grid_list = list(ParameterGrid(param_grid))\n",
    "param_grid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# scaling = ['z_score', 'minmax', 'none']\n",
    "# conduct_Czrrf = [True, False]\n",
    "# at_each_time_point = [True, False]\n",
    "scaling = ['minmax']\n",
    "conduct_Czrrf = [True, False]\n",
    "at_each_time_point = [True]\n",
    "across_channel = [True]\n",
    "\n",
    "if scaling == 'z_score':\n",
    "    z_score = True\n",
    "    minmax = False\n",
    "elif scaling == 'minmax':\n",
    "    z_score = False\n",
    "    minmax = True \n",
    "else:\n",
    "    z_score = False\n",
    "    minmax = False \n",
    "\n",
    "# Create multiple parameter set based on all posible combination of the parameter grids\n",
    "param_grid = [\n",
    "                 {'scaling': ['z_score', 'minmax', 'none'], \n",
    "                  'conduct_Czrrf': [True, False], \n",
    "                  'at_each_time_point': [True],\n",
    "                  'across_channel': [True],\n",
    "                  'dropout_rate': [0.5],\n",
    "                  'lr': [0.001, 0.01]},\n",
    "                 {'scaling':  ['z_score', 'minmax'], \n",
    "                  'conduct_Czrrf': [True, False],\n",
    "                  'at_each_time_point': [False],\n",
    "                  'across_channel': [True, False],\n",
    "                  'dropout_rate': [0.5],\n",
    "                  'lr': [0.001, 0.01]},\n",
    "                ]\n",
    "param_grid_list = list(ParameterGrid(param_grid))\n",
    "param_grid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independant test: \n",
    "model were trained by all training data (data['train_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'EEGNet_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mEEGNet_function\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EEGNet\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mData_Preprocess_EEGNet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data_Preprocess_EEGNet\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'EEGNet_function'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from EEGNet_function import EEGNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from Data_Preprocess_EEGNet import Data_Preprocess_EEGNet\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# apply grid search for optimal hyperparameters\n",
    "# grid = {'dropout_rate': [0.5],\n",
    "#         'lr': [0.001, 0.0001]}\n",
    "\n",
    "\n",
    "for idx_grid_search, params in enumerate(param_grid_list):\n",
    "    print('params:', params)\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    conduct_Czrrf = params['conduct_Czrrf']\n",
    "    lr = params['lr']\n",
    "    at_each_time_point = params['at_each_time_point']\n",
    "    if at_each_time_point == True:\n",
    "        across_channel = True\n",
    "    else:\n",
    "        across_channel = params['across_channel']\n",
    "        \n",
    "    scaling = params['scaling']\n",
    "    if scaling == 'z_score':\n",
    "        z_score = True\n",
    "        minmax = False\n",
    "    elif scaling == 'minmax':\n",
    "        z_score = False\n",
    "        minmax = True \n",
    "    else:\n",
    "        z_score = False\n",
    "        minmax = False    \n",
    "    \n",
    "        \n",
    "    # preprocess\n",
    "    Freq = target_Freq\n",
    "    if Freq == 500:\n",
    "        DPE = Data_Preprocess_EEGNet(data, info, conduct_decimate=False, conduct_Czrrf=conduct_Czrrf, across_channel=across_channel,\n",
    "                                    conduct_filter=conduct_filter, band=band, at_each_time_point=at_each_time_point,\n",
    "                                    sec_Window=sec_Window, sec_Overlap=sec_Overlap)\n",
    "    else:\n",
    "        DPE = Data_Preprocess_EEGNet(data, info, target_Freq=Freq, conduct_Czrrf=conduct_Czrrf, across_channel=across_channel,\n",
    "                                    conduct_filter=conduct_filter, band=band, at_each_time_point=at_each_time_point,\n",
    "                                    sec_Window=sec_Window, sec_Overlap=sec_Overlap)\n",
    "    \n",
    "    PP_data, label_ndarrays, label_ndarrays_CInonCI = DPE.epoch_based_organizing(z_score=z_score, minmax=minmax)\n",
    "    segment_shape = PP_data['train_valid'][0].shape\n",
    "    \n",
    "    Y_perFold = {'train_valid':list(),'test':list()}\n",
    "    evaluation_perFold = {'train_valid':list(),'test':list()}\n",
    "    \n",
    "    # Define the model architecture\n",
    "    k_length = int(Freq/2)\n",
    "    model = EEGNet(input_shape=segment_shape,\n",
    "               num_class=2,\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               optimizer=Adam(beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "               epochs=500,\n",
    "               batch_size=100,\n",
    "               es_patience=200,\n",
    "               monitor='val_accuracy',\n",
    "               log_path = f'logs/Independant',\n",
    "               dropout_rate = dropout_rate,\n",
    "               kernLength = int(Freq/2),\n",
    "               lr = lr,\n",
    "               min_lr = lr/10,  \n",
    "               shuffle = True)\n",
    "    \n",
    "    # Fit data to model\n",
    "    model.fit(PP_data['train_valid'], label_ndarrays_CInonCI['train_valid'], PP_data['test'], label_ndarrays_CInonCI['test'])\n",
    "    \n",
    "    # evaluation\n",
    "    keys = data.keys()\n",
    "    for key in keys:\n",
    "        if (key != 'train') | (key != 'valid'):\n",
    "            Y,evaluation = model.predict(PP_data[key], label_ndarrays_CInonCI[key])\n",
    "            evaluation_perFold[key].append(evaluation)\n",
    "            Y_perFold[key].append(Y)\n",
    "        else: pass\n",
    "    \n",
    "    # save results\n",
    "    for key, value in evaluation_perFold.items():\n",
    "        evaluation_perFold[key] = pd.DataFrame(value)\n",
    "    \n",
    "    folder_path = f'./Results/EEGNet/5Fold test(k_length={k_length}, Fs={target_Freq})/z-score={z_score}, minmax={minmax}, at_each_time_point={at_each_time_point}, across_channel={across_channel}/{dropout_rate},{lr},conduct_Czrrf={conduct_Czrrf}/independant test'\n",
    "    if not os.path.exists(folder_path):    os.makedirs(folder_path)\n",
    "    \n",
    "    # save evaluation to .csv\n",
    "    [value.to_csv(os.path.join(folder_path, f'evaluation_{key}.csv')) for key, value in evaluation_perFold.items()]\n",
    "    \n",
    "    # save true and predicted label to pickle\n",
    "    with open(os.path.join(folder_path, f'Y_perFold.pkl'), 'wb') as handle:\n",
    "        pickle.dump(Y_perFold, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # save subject-based evaluation to .csv\n",
    "    subject_correct = {}\n",
    "    subject_accuracy = {}\n",
    "    subject_true_label = {}\n",
    "    subject_pred_label = {}\n",
    "    for key, value in Y_perFold.items():\n",
    "        subject_accuracy[key] = []\n",
    "        for Y in Y_perFold[key]:\n",
    "            subject_correct[key], accuracy, subject_true_label[key], subject_pred_label[key] = subject_based_accuracy(Y)\n",
    "            subject_accuracy[key].append(accuracy)\n",
    "        subject_accuracy[key] = pd.DataFrame(subject_accuracy[key])\n",
    "        subject_accuracy[key].to_csv(os.path.join(folder_path, f'subject-based evaluation_{key}.csv'))\n",
    "        print(f'{key}:{subject_accuracy[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPR, TNR computation\n",
    "- load the Y_perfold.pkl data\n",
    "- compute TPR, TNR for test\n",
    "- (develping) compute average TPR, TNR among all fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load true and predicted label to pickle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Results/EEGNet/5Fold test(k_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,CZrrf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfolder_path:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_perFold.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k_length' is not defined"
     ]
    }
   ],
   "source": [
    "# load true and predicted label to pickle\n",
    "folder_path = f'./Results/EEGNet/5Fold test(k_length={k_length}, Fs={Freq})/{dropout_rate},{lr},CZrrf'\n",
    "print(f'folder_path:{folder_path}')\n",
    "with open(os.path.join(folder_path, 'Y_perFold.pkl'), 'rb') as handle:\n",
    "    Y_perFold = pickle.load(handle)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# save subject-based evaluation to .csv\n",
    "subject_correct = {}\n",
    "subject_accuracy = {}\n",
    "subject_true_label = {}\n",
    "subject_pred_label = {}\n",
    "for key, value in Y_perFold.items():\n",
    "    subject_accuracy[key] = []\n",
    "    for Y in Y_perFold[key]:\n",
    "        subject_correct[key], accuracy, subject_true_label[key], subject_pred_label[key] = subject_based_accuracy(Y)\n",
    "        subject_accuracy[key].append(accuracy)\n",
    "    subject_accuracy[key] = pd.DataFrame(subject_accuracy[key])\n",
    "    # subject_accuracy[key].to_csv(os.path.join(folder_path, f'subject-based evaluation_{key}.csv'))\n",
    "    print(f'{key}:{subject_accuracy[key]}')\n",
    "    \n",
    "# ------------------------------------------------------------------------------\n",
    "# test results\n",
    "print(subject_correct['test'].shape)\n",
    "subject_true_label = info['test'].Label.values\n",
    "print(subject_true_label)\n",
    "subject_true_label = np.where(subject_true_label == 2, 1, subject_true_label)\n",
    "print(subject_true_label.shape)\n",
    "\n",
    "subject_predic_label = []\n",
    "for i, correct in enumerate(subject_correct['test']):\n",
    "    # print(i,correct)\n",
    "    if correct == 1:\n",
    "        subject_predic_label.append(subject_true_label[i])\n",
    "    else:\n",
    "        subject_predic_label.append(np.abs(1-subject_true_label[i]))\n",
    "subject_predic_label = np.array(subject_predic_label)\n",
    "\n",
    "print(subject_true_label)\n",
    "print(subject_correct['test'])\n",
    "print(subject_predic_label)\n",
    "\n",
    "confusion_matrix = confusion_matrix(subject_true_label, subject_predic_label)\n",
    "print(confusion_matrix)\n",
    "TN, FP, FN, TP = confusion_matrix.ravel()\n",
    "print(f'TN:{TN}, FP:{FP}, FN:{FN}, TP:{TP}')\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "print('TPR, TNR:',TPR, TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load true and predicted label to pickle\n",
    "k_length = 62\n",
    "Freq = 125\n",
    "folder_path = f'./Results/EEGNet/5Fold test(k_length={k_length}, Fs={Freq})/{dropout_rate},{lr}'\n",
    "print(f'folder_path:{folder_path}')\n",
    "with open(os.path.join(folder_path, 'Y_perFold.pkl'), 'rb') as handle:\n",
    "    Y_perFold = pickle.load(handle)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# save subject-based evaluation to .csv\n",
    "subject_correct = {}\n",
    "subject_accuracy = {}\n",
    "subject_true_label = {}\n",
    "subject_pred_label = {}\n",
    "subject_TPR = {}\n",
    "subject_TNR = {}\n",
    "for key, value in Y_perFold.items():\n",
    "    subject_accuracy[key] = []\n",
    "    subject_TPR[key] = []\n",
    "    subject_TNR[key] = []\n",
    "    for Y in Y_perFold[key]:\n",
    "        subject_correct[key], accuracy, subject_true_label[key], subject_pred_label[key] = subject_based_accuracy(Y)\n",
    "        # print(f'subject_true_label[{key}]:{type(subject_true_label[key])}\\n',subject_true_label[key])\n",
    "        # print(f'subject_pred_label[{key}]:{type(subject_pred_label[key])}\\n',subject_pred_label[key])\n",
    "        confusion_matrix_object = confusion_matrix(subject_true_label[key], subject_pred_label[key])\n",
    "        # print(confusion_matrix_object)\n",
    "        TN, FP, FN, TP = confusion_matrix_object.ravel()\n",
    "        # print(f'TN:{TN}, FP:{FP}, FN:{FN}, TP:{TP}')\n",
    "        \n",
    "        TPR = TP/(TP+FN)\n",
    "        TNR = TN/(TN+FP)\n",
    "        # print('TPR, TNR:',TPR, TNR)\n",
    "        \n",
    "        subject_accuracy[key].append(accuracy)\n",
    "        subject_TPR[key].append(TPR)\n",
    "        subject_TNR[key].append(TNR)\n",
    "\n",
    "    print('---------------------------------------')\n",
    "    subject_accuracy[key] = pd.DataFrame(subject_accuracy[key])\n",
    "    # subject_accuracy[key].to_csv(os.path.join(folder_path, f'subject-based evaluation_{key}.csv'))\n",
    "    print(f'subject_accuracy of {key}:\\n{subject_accuracy[key]}')\n",
    "    print(f'average:{subject_accuracy[key].mean()}')\n",
    "\n",
    "    subject_TPR[key] = pd.DataFrame(subject_TPR[key])\n",
    "    # subject_accuracy[key].to_csv(os.path.join(folder_path, f'subject-based evaluation_{key}.csv'))\n",
    "    print(f'subject_TPR of {key}:\\n{subject_TPR[key]}')\n",
    "    print(f'average:{subject_TPR[key].mean()}')\n",
    "\n",
    "    subject_TNR[key] = pd.DataFrame(subject_TNR[key])\n",
    "    # subject_accuracy[key].to_csv(os.path.join(folder_path, f'subject-based evaluation_{key}.csv'))\n",
    "    print(f'subject_TNR of {key}:\\n{subject_TNR[key]}')\n",
    "    print(f'average:{subject_TNR[key].mean()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFGPU_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
